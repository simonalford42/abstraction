Using torch device NVIDIA GeForce RTX 3090
net: causal
cc_weight: 1.0
abstract_pen: 1.0
params: {'epochs': 100, 'lr': 0.0008, 'n': 5000}
Net has 207442 parameters
Round 0
Generated trajectories in 72.7 seconds
epoch: 0	train loss: 181775.09375	(17.2s)
epoch: 1	train loss: 172603.84375	(16.1s)
epoch: 2	train loss: 138774.734375	(16.1s)
epoch: 3	train loss: 122714.59375	(16.2s)
epoch: 4	train loss: 111539.375	(16.1s)
epoch: 5	train loss: 103809.8203125	(16.2s)
epoch: 6	train loss: 98128.171875	(16.1s)
epoch: 7	train loss: 94356.5	(16.1s)
epoch: 8	train loss: 92114.4765625	(16.1s)
epoch: 9	train loss: 90303.6015625	(16.1s)
epoch: 10	train loss: 88792.5625	(16.1s)
epoch: 11	train loss: 87183.25	(16.2s)
epoch: 12	train loss: 86153.5	(16.1s)
epoch: 13	train loss: 85369.84375	(16.1s)
epoch: 14	train loss: 84154.3984375	(16.1s)
epoch: 15	train loss: 82875.59375	(16.1s)
epoch: 16	train loss: 81617.25	(16.1s)
epoch: 17	train loss: 80282.671875	(16.1s)
epoch: 18	train loss: 79124.359375	(16.1s)
epoch: 19	train loss: 78328.8203125	(16.2s)
epoch: 20	train loss: 77481.8203125	(16.2s)
epoch: 21	train loss: 76299.8203125	(16.1s)
epoch: 22	train loss: 75550.2734375	(16.2s)
epoch: 23	train loss: 74792.875	(16.1s)
epoch: 24	train loss: 74386.3046875	(16.1s)
epoch: 25	train loss: 73859.9140625	(16.1s)
epoch: 26	train loss: 72880.84375	(16.1s)
epoch: 27	train loss: 72246.0625	(16.2s)
epoch: 28	train loss: 72448.2578125	(16.2s)
epoch: 29	train loss: 72818.15625	(16.2s)
epoch: 30	train loss: 71164.96875	(16.1s)
epoch: 31	train loss: 70809.5546875	(16.1s)
epoch: 32	train loss: 69835.6875	(16.1s)
epoch: 33	train loss: 69637.421875	(16.1s)
epoch: 34	train loss: 68732.5234375	(16.1s)
epoch: 35	train loss: 68268.6640625	(16.1s)
epoch: 36	train loss: 67639.2421875	(16.1s)
epoch: 37	train loss: 67081.6640625	(16.1s)
epoch: 38	train loss: 66460.53125	(16.1s)
epoch: 39	train loss: 66175.21875	(16.1s)
epoch: 40	train loss: 65579.7890625	(16.1s)
epoch: 41	train loss: 65188.7578125	(16.1s)
epoch: 42	train loss: 65010.61328125	(16.1s)
epoch: 43	train loss: 64513.87890625	(16.1s)
epoch: 44	train loss: 64153.51171875	(16.1s)
epoch: 45	train loss: 63550.38671875	(16.2s)
epoch: 46	train loss: 63426.703125	(16.1s)
epoch: 47	train loss: 62199.30078125	(16.2s)
epoch: 48	train loss: 62943.39453125	(16.1s)
epoch: 49	train loss: 62950.0234375	(16.1s)
epoch: 50	train loss: 63650.11328125	(16.1s)
epoch: 51	train loss: 63079.62109375	(16.2s)
epoch: 52	train loss: 62111.4609375	(16.1s)
epoch: 53	train loss: 61046.61328125	(16.2s)
epoch: 54	train loss: 61102.5859375	(16.1s)
epoch: 55	train loss: 60192.1328125	(16.1s)
epoch: 56	train loss: 60458.8671875	(16.1s)
epoch: 57	train loss: 60481.5078125	(16.1s)
epoch: 58	train loss: 58536.92578125	(16.1s)
epoch: 59	train loss: 58518.80859375	(16.1s)
epoch: 60	train loss: 58425.765625	(16.1s)
epoch: 61	train loss: 58295.47265625	(16.1s)
epoch: 62	train loss: 57993.85546875	(16.1s)
epoch: 63	train loss: 57859.1953125	(16.1s)
epoch: 64	train loss: 57550.68359375	(16.1s)
epoch: 65	train loss: 57191.52734375	(16.2s)
epoch: 66	train loss: 57699.3984375	(16.1s)
epoch: 67	train loss: 57768.7421875	(16.1s)
epoch: 68	train loss: 57467.55859375	(16.1s)
epoch: 69	train loss: 60059.31640625	(16.1s)
epoch: 70	train loss: 58636.34765625	(16.1s)
epoch: 71	train loss: 57355.28515625	(16.2s)
epoch: 72	train loss: 56957.84375	(16.1s)
epoch: 73	train loss: 56145.88671875	(16.1s)
epoch: 74	train loss: 55539.34375	(16.1s)
epoch: 75	train loss: 55446.09375	(16.2s)
epoch: 76	train loss: 55101.0625	(16.1s)
epoch: 77	train loss: 54871.24609375	(16.1s)
epoch: 78	train loss: 54155.921875	(16.1s)
epoch: 79	train loss: 53553.28125	(16.1s)
epoch: 80	train loss: 53222.4375	(16.1s)
epoch: 81	train loss: 52537.05859375	(16.1s)
epoch: 82	train loss: 51961.7890625	(16.1s)
epoch: 83	train loss: 51325.4296875	(16.1s)
epoch: 84	train loss: 50943.44921875	(16.2s)
epoch: 85	train loss: 50482.7265625	(16.1s)
epoch: 86	train loss: 50140.9921875	(16.1s)
epoch: 87	train loss: 49643.25390625	(16.1s)
epoch: 88	train loss: 49324.52734375	(16.1s)
epoch: 89	train loss: 48972.45703125	(16.1s)
epoch: 90	train loss: 48600.75390625	(16.1s)
epoch: 91	train loss: 48315.875	(16.2s)
epoch: 92	train loss: 48063.68359375	(16.1s)
epoch: 93	train loss: 47779.14453125	(16.2s)
epoch: 94	train loss: 47699.8515625	(16.1s)
epoch: 95	train loss: 47716.625	(16.1s)
epoch: 96	train loss: 47742.05078125	(16.1s)
epoch: 97	train loss: 48025.00390625	(16.1s)
epoch: 98	train loss: 48306.3671875	(16.2s)
epoch: 99	train loss: 48529.984375	(16.1s)
Evaluating model on 200 episodes
0.0004633201363806923
0.0025791648513404652
0.0013491644349414855
0.0002829914155881852
0.001709742413368076
0.0012071976670995355
0.0023983276914805174
0.002737192058702931
0.0007540784135926515
0.00048553853412158787
0.0018366343768623967
0.0015905380326633651
0.0016715360106900334
0.00027821012190543115
0.0007732791273156181
0.001642320945393294
0.0024306539756556353
0.0012438743433449417
Solved 18/200 episodes
0.00012716882275223422
Evaluated model in 27.6 seconds
Saved model for run
e58cb3f68e74461db96fef71db8b8796 with name round-0
Round 1
Generated trajectories in 72.9 seconds
epoch: 0	train loss: 65111.17578125	(16.3s)
epoch: 1	train loss: 60926.8125	(16.1s)
epoch: 2	train loss: 58668.0078125	(16.1s)
epoch: 3	train loss: 57002.4140625	(16.1s)
epoch: 4	train loss: 55670.13671875	(16.1s)
epoch: 5	train loss: 54526.3828125	(16.1s)
epoch: 6	train loss: 53452.625	(16.1s)
epoch: 7	train loss: 52569.52734375	(16.2s)
epoch: 8	train loss: 51629.40625	(16.1s)
epoch: 9	train loss: 50955.8125	(16.1s)
epoch: 10	train loss: 50059.76171875	(16.1s)
epoch: 11	train loss: 49209.78515625	(16.1s)
epoch: 12	train loss: 48574.55859375	(16.1s)
epoch: 13	train loss: 48042.67578125	(16.1s)
epoch: 14	train loss: 47491.25390625	(16.1s)
epoch: 15	train loss: 47031.828125	(16.1s)
epoch: 16	train loss: 46365.09375	(16.1s)
epoch: 17	train loss: 45801.58203125	(16.1s)
epoch: 18	train loss: 45502.5625	(16.1s)
epoch: 19	train loss: 45157.49609375	(16.1s)
epoch: 20	train loss: 44862.1015625	(16.1s)
epoch: 21	train loss: 44382.703125	(16.2s)
epoch: 22	train loss: 43948.0703125	(16.0s)
epoch: 23	train loss: 43661.10546875	(16.0s)
epoch: 24	train loss: 43007.3984375	(15.9s)
epoch: 25	train loss: 42680.0234375	(15.9s)
epoch: 26	train loss: 42645.546875	(16.0s)
epoch: 27	train loss: 42024.58203125	(15.9s)
epoch: 28	train loss: 42164.2265625	(16.0s)
epoch: 29	train loss: 41990.703125	(16.0s)
epoch: 30	train loss: 41653.703125	(16.0s)
epoch: 31	train loss: 41043.734375	(16.0s)
epoch: 32	train loss: 40497.796875	(16.0s)
epoch: 33	train loss: 40483.21875	(16.0s)
epoch: 34	train loss: 40618.08203125	(16.0s)
epoch: 35	train loss: 40231.17578125	(16.0s)
epoch: 36	train loss: 40104.546875	(16.0s)
epoch: 37	train loss: 39709.921875	(16.0s)
epoch: 38	train loss: 39384.39453125	(16.0s)
epoch: 39	train loss: 39087.80859375	(16.0s)
epoch: 40	train loss: 38826.1171875	(16.0s)
epoch: 41	train loss: 38625.2890625	(16.0s)
epoch: 42	train loss: 38922.30078125	(16.0s)
epoch: 43	train loss: 39035.63671875	(16.0s)
epoch: 44	train loss: 38620.8828125	(15.9s)
epoch: 45	train loss: 37962.359375	(16.0s)
epoch: 46	train loss: 37047.4296875	(16.0s)
epoch: 47	train loss: 36548.0859375	(16.0s)
epoch: 48	train loss: 36244.6875	(15.9s)
epoch: 49	train loss: 36131.7734375	(16.0s)
epoch: 50	train loss: 36124.0546875	(16.0s)
epoch: 51	train loss: 36320.13671875	(16.0s)
epoch: 52	train loss: 36660.54296875	(16.0s)
epoch: 53	train loss: 36616.99609375	(16.0s)
epoch: 54	train loss: 36541.8125	(16.0s)
epoch: 55	train loss: 36556.17578125	(16.0s)
epoch: 56	train loss: 36797.1171875	(16.0s)
epoch: 57	train loss: 37357.49609375	(16.0s)
epoch: 58	train loss: 37280.37109375	(15.9s)
epoch: 59	train loss: 36691.875	(16.0s)
epoch: 60	train loss: 36379.03125	(16.0s)
epoch: 61	train loss: 36165.8828125	(16.0s)
epoch: 62	train loss: 36057.890625	(16.0s)
epoch: 63	train loss: 35467.390625	(16.0s)
epoch: 64	train loss: 35053.85546875	(16.0s)
epoch: 65	train loss: 34624.3125	(16.0s)
epoch: 66	train loss: 34401.78515625	(16.0s)
epoch: 67	train loss: 34235.6484375	(16.0s)
epoch: 68	train loss: 33725.90625	(16.0s)
epoch: 69	train loss: 33282.6875	(16.0s)
epoch: 70	train loss: 33247.33203125	(16.0s)
epoch: 71	train loss: 32811.765625	(16.0s)
epoch: 72	train loss: 32614.048828125	(16.0s)
epoch: 73	train loss: 32550.615234375	(15.9s)
epoch: 74	train loss: 32276.376953125	(16.0s)
epoch: 75	train loss: 31765.220703125	(16.0s)
epoch: 76	train loss: 31426.8359375	(16.0s)
epoch: 77	train loss: 31174.353515625	(16.0s)
epoch: 78	train loss: 31367.53125	(16.0s)
epoch: 79	train loss: 31520.7109375	(16.0s)
epoch: 80	train loss: 31661.505859375	(16.0s)
epoch: 81	train loss: 31580.580078125	(16.0s)
epoch: 82	train loss: 31803.642578125	(15.9s)
epoch: 83	train loss: 31916.8125	(16.0s)
epoch: 84	train loss: 31501.09375	(16.0s)
epoch: 85	train loss: 31334.220703125	(16.0s)
epoch: 86	train loss: 31406.57421875	(16.0s)
epoch: 87	train loss: 31142.0546875	(15.9s)
epoch: 88	train loss: 31177.529296875	(16.0s)
epoch: 89	train loss: 31419.49609375	(16.0s)
epoch: 90	train loss: 31723.998046875	(16.0s)
epoch: 91	train loss: 31580.3671875	(15.9s)
epoch: 92	train loss: 31867.810546875	(15.9s)
epoch: 93	train loss: 31394.056640625	(16.0s)
epoch: 94	train loss: 31625.44140625	(15.9s)
epoch: 95	train loss: 32105.7265625	(16.0s)
epoch: 96	train loss: 32827.78125	(16.0s)
epoch: 97	train loss: 33039.25	(16.0s)
epoch: 98	train loss: 32493.111328125	(16.0s)
epoch: 99	train loss: 32403.71875	(15.9s)
Evaluating model on 200 episodes
0.0013731857761740685
0.002194622647948563
0.0016083708324003965
0.0008254449930973351
0.0023663637111894786
0.0019815529230982065
0.002553357626311481
0.0022712716599926353
0.0022603789111599326
0.0014599418500438333
0.005450351862236857
0.0016221797559410334
0.0011711359693435952
0.0018909284262917936
0.00370778632350266
0.00264529837295413
0.0038750940390552082
0.0020774364820681512
0.0005405561241786927
0.0015055741387186572
0.0015597392048221081
0.0030062260339036584
0.0019410966779105365
0.00143167853821069
0.0028545432044969252
0.0008172475172614213
0.00154639218817465
0.0013796928396914154
0.0045967778423801064
0.006739939737599343
Solved 30/200 episodes
0.00034627083105078784
Evaluated model in 26.9 seconds
Saved model for run
e58cb3f68e74461db96fef71db8b8796 with name round-1
Round 2
Generated trajectories in 71.6 seconds
epoch: 0	train loss: 69326.0546875	(16.0s)
epoch: 1	train loss: 58675.265625	(16.0s)
epoch: 2	train loss: 54619.44140625	(16.1s)
epoch: 3	train loss: 51904.20703125	(16.0s)
epoch: 4	train loss: 49974.875	(16.1s)
epoch: 5	train loss: 48183.08203125	(16.1s)
epoch: 6	train loss: 46581.8046875	(16.1s)
epoch: 7	train loss: 45384.17578125	(16.0s)
epoch: 8	train loss: 44358.90234375	(16.1s)
epoch: 9	train loss: 43394.3984375	(16.0s)
epoch: 10	train loss: 42487.15234375	(16.1s)
epoch: 11	train loss: 41363.8125	(16.0s)
epoch: 12	train loss: 40563.8046875	(16.1s)
epoch: 13	train loss: 39919.515625	(16.0s)
epoch: 14	train loss: 39215.171875	(16.1s)
epoch: 15	train loss: 38580.92578125	(16.1s)
epoch: 16	train loss: 37848.4609375	(16.1s)
epoch: 17	train loss: 37235.90625	(16.0s)
epoch: 18	train loss: 36776.08984375	(16.0s)
epoch: 19	train loss: 36261.48046875	(16.0s)
epoch: 20	train loss: 35918.0234375	(16.1s)
epoch: 21	train loss: 35466.1953125	(16.1s)
epoch: 22	train loss: 35250.328125	(16.1s)
epoch: 23	train loss: 34933.73828125	(16.0s)
epoch: 24	train loss: 35392.2890625	(16.0s)
epoch: 25	train loss: 34175.0234375	(16.1s)
epoch: 26	train loss: 33541.9375	(16.2s)
epoch: 27	train loss: 33381.91796875	(16.1s)
epoch: 28	train loss: 33417.65625	(16.1s)
epoch: 29	train loss: 33318.98828125	(16.1s)
epoch: 30	train loss: 33541.46484375	(16.1s)
epoch: 31	train loss: 33789.27734375	(16.2s)
epoch: 32	train loss: 33246.17578125	(16.1s)
epoch: 33	train loss: 32728.224609375	(16.1s)
epoch: 34	train loss: 32118.759765625	(16.1s)
epoch: 35	train loss: 31919.74609375	(16.1s)
epoch: 36	train loss: 31780.0234375	(16.2s)
epoch: 37	train loss: 31449.939453125	(16.1s)
epoch: 38	train loss: 31347.341796875	(16.2s)
epoch: 39	train loss: 31156.01953125	(16.1s)
epoch: 40	train loss: 31554.39453125	(16.2s)
epoch: 41	train loss: 31910.56640625	(16.1s)
epoch: 42	train loss: 31379.302734375	(16.2s)
epoch: 43	train loss: 30653.33984375	(16.1s)
epoch: 44	train loss: 30191.236328125	(16.1s)
epoch: 45	train loss: 30167.044921875	(16.1s)
epoch: 46	train loss: 29333.11328125	(16.1s)
epoch: 47	train loss: 28950.802734375	(16.2s)
epoch: 48	train loss: 28519.83984375	(16.2s)
epoch: 49	train loss: 28506.19921875	(16.2s)
epoch: 50	train loss: 28644.875	(16.1s)
epoch: 51	train loss: 28178.3984375	(16.1s)
epoch: 52	train loss: 28699.318359375	(16.2s)
epoch: 53	train loss: 28272.55859375	(16.1s)
epoch: 54	train loss: 28208.75390625	(16.1s)
epoch: 55	train loss: 27978.4453125	(16.1s)
epoch: 56	train loss: 27393.705078125	(16.1s)
epoch: 57	train loss: 27226.34765625	(16.2s)
epoch: 58	train loss: 27310.51171875	(16.2s)
epoch: 59	train loss: 27189.234375	(16.1s)
epoch: 60	train loss: 27264.119140625	(16.1s)
epoch: 61	train loss: 27373.15234375	(16.1s)
epoch: 62	train loss: 27708.92578125	(16.1s)
epoch: 63	train loss: 28272.984375	(16.2s)
epoch: 64	train loss: 28057.546875	(16.1s)
epoch: 65	train loss: 27287.705078125	(16.1s)
epoch: 66	train loss: 27075.458984375	(16.1s)
epoch: 67	train loss: 28515.9921875	(16.1s)
epoch: 68	train loss: 27676.8125	(16.2s)
epoch: 69	train loss: 27270.66015625	(16.1s)
epoch: 70	train loss: 26948.6796875	(16.2s)
epoch: 71	train loss: 26887.6171875	(16.2s)
epoch: 72	train loss: 26760.75	(16.2s)
epoch: 73	train loss: 26632.48046875	(16.2s)
epoch: 74	train loss: 26641.8515625	(16.1s)
epoch: 75	train loss: 26586.62109375	(16.1s)
epoch: 76	train loss: 26749.86328125	(16.2s)
epoch: 77	train loss: 27245.873046875	(16.1s)
epoch: 78	train loss: 27248.013671875	(16.2s)
epoch: 79	train loss: 27476.0390625	(16.1s)
epoch: 80	train loss: 27024.685546875	(16.1s)
epoch: 81	train loss: 26878.8359375	(16.1s)
epoch: 82	train loss: 26061.22265625	(16.1s)
epoch: 83	train loss: 25435.9765625	(16.1s)
epoch: 84	train loss: 25337.39453125	(16.2s)
epoch: 85	train loss: 25328.787109375	(16.1s)
epoch: 86	train loss: 25584.166015625	(16.1s)
epoch: 87	train loss: 25677.5859375	(16.2s)
epoch: 88	train loss: 25453.875	(16.1s)
epoch: 89	train loss: 25477.3359375	(16.1s)
epoch: 90	train loss: 25397.83984375	(16.1s)
epoch: 91	train loss: 25737.5	(16.1s)
epoch: 92	train loss: 25395.12109375	(16.2s)
epoch: 93	train loss: 25235.69921875	(16.1s)
epoch: 94	train loss: 25242.84375	(16.2s)
epoch: 95	train loss: 25217.708984375	(16.1s)
epoch: 96	train loss: 25489.0234375	(16.1s)
epoch: 97	train loss: 26017.85546875	(16.1s)
epoch: 98	train loss: 25457.564453125	(16.2s)
epoch: 99	train loss: 24852.169921875	(16.1s)
Evaluating model on 200 episodes
0.0017573126242496073
0.00647835765266791
0.0026562389684841037
0.008239966176915914
0.002170095918700099
0.0019103684462606907
0.002765481825917959
0.004335914883995429
0.003541077234937499
0.0012757565127685666
0.0002499258844181895
0.001959814806468785
0.0083226925926283
0.0017100681240359943
0.003725522430613637
0.0003354492655489594
0.005993066830948616
0.0023942869156599045
0.002544402979159107
0.0004934091557515785
0.0021200525225140154
0.0076524491887539625
0.0022700069239363074
0.0033109780051745474
0.0051223644986748695
0.001946249627508223
0.005735974118579179
0.0057171120861312374
0.003917517722584307
0.0018355830106884241
0.004371407674625516
0.000605774053838104
0.0035165459848940372
0.003706342385460933
0.0004877240862697363
0.012071114964783192
0.004713401373010129
0.0030346894442724683
Solved 38/200 episodes
0.0006749724845091501
Evaluated model in 25.2 seconds
Saved model for run
e58cb3f68e74461db96fef71db8b8796 with name round-2
Round 3
Generated trajectories in 72.8 seconds
epoch: 0	train loss: 75614.765625	(16.2s)
epoch: 1	train loss: 60932.42578125	(16.3s)
epoch: 2	train loss: 55064.11328125	(16.2s)
epoch: 3	train loss: 51441.24609375	(16.2s)
epoch: 4	train loss: 48625.5078125	(16.2s)
epoch: 5	train loss: 46680.13671875	(16.2s)
epoch: 6	train loss: 44930.13671875	(16.2s)
epoch: 7	train loss: 43317.4140625	(16.2s)
epoch: 8	train loss: 42636.6875	(16.2s)
epoch: 9	train loss: 41371.5390625	(16.3s)
epoch: 10	train loss: 40184.76953125	(16.3s)
epoch: 11	train loss: 39057.8828125	(16.4s)
epoch: 12	train loss: 38116.6953125	(16.2s)
epoch: 13	train loss: 37371.85546875	(16.3s)
epoch: 14	train loss: 36806.00390625	(16.2s)
epoch: 15	train loss: 36193.92578125	(16.3s)
epoch: 16	train loss: 35607.94921875	(16.3s)
epoch: 17	train loss: 34841.265625	(16.3s)
epoch: 18	train loss: 34197.08984375	(16.2s)
epoch: 19	train loss: 33561.35546875	(16.2s)
epoch: 20	train loss: 33325.53125	(16.3s)
epoch: 21	train loss: 32856.28125	(16.3s)
epoch: 22	train loss: 32246.462890625	(16.2s)
epoch: 23	train loss: 32215.6796875	(16.2s)
epoch: 24	train loss: 32354.720703125	(16.2s)
epoch: 25	train loss: 31676.693359375	(16.3s)
epoch: 26	train loss: 31901.66796875	(16.2s)
epoch: 27	train loss: 31786.216796875	(16.2s)
epoch: 28	train loss: 31444.390625	(16.2s)
epoch: 29	train loss: 31572.087890625	(16.3s)
epoch: 30	train loss: 30934.5625	(16.3s)
epoch: 31	train loss: 30427.9765625	(16.3s)
epoch: 32	train loss: 30105.158203125	(16.2s)
epoch: 33	train loss: 29374.28515625	(16.3s)
epoch: 34	train loss: 28980.8515625	(16.2s)
epoch: 35	train loss: 28594.80859375	(16.4s)
epoch: 36	train loss: 28677.73828125	(16.3s)
epoch: 37	train loss: 28275.638671875	(16.3s)
epoch: 38	train loss: 28043.169921875	(16.3s)
epoch: 39	train loss: 27855.673828125	(16.2s)
epoch: 40	train loss: 27675.38671875	(16.3s)
epoch: 41	train loss: 27566.349609375	(16.2s)
epoch: 42	train loss: 27651.763671875	(16.2s)
epoch: 43	train loss: 27610.11328125	(16.2s)
epoch: 44	train loss: 27266.638671875	(16.2s)
epoch: 45	train loss: 27623.490234375	(16.2s)
epoch: 46	train loss: 27308.912109375	(16.2s)
epoch: 47	train loss: 26863.873046875	(16.2s)
epoch: 48	train loss: 26871.982421875	(16.3s)
epoch: 49	train loss: 26300.298828125	(16.2s)
epoch: 50	train loss: 26461.869140625	(16.2s)
epoch: 51	train loss: 25935.849609375	(16.2s)
epoch: 52	train loss: 25820.0703125	(16.2s)
epoch: 53	train loss: 26405.67578125	(16.3s)
epoch: 54	train loss: 26229.119140625	(16.3s)
epoch: 55	train loss: 25921.08984375	(16.3s)
epoch: 56	train loss: 25735.044921875	(16.2s)
epoch: 57	train loss: 25640.84375	(16.2s)
epoch: 58	train loss: 25843.201171875	(16.2s)
epoch: 59	train loss: 25595.314453125	(16.2s)
epoch: 60	train loss: 25465.861328125	(16.2s)
epoch: 61	train loss: 25125.58984375	(16.2s)
epoch: 62	train loss: 24792.580078125	(16.2s)
epoch: 63	train loss: 24640.634765625	(16.3s)
epoch: 64	train loss: 24438.064453125	(16.2s)
epoch: 65	train loss: 24368.384765625	(16.2s)
epoch: 66	train loss: 24362.32421875	(16.2s)
epoch: 67	train loss: 24948.470703125	(16.2s)
epoch: 68	train loss: 24103.779296875	(16.2s)
epoch: 69	train loss: 23885.8515625	(16.2s)
epoch: 70	train loss: 24054.43359375	(16.2s)
epoch: 71	train loss: 24129.404296875	(16.2s)
epoch: 72	train loss: 24288.158203125	(16.2s)
epoch: 73	train loss: 24866.634765625	(16.3s)
epoch: 74	train loss: 24202.875	(16.2s)
epoch: 75	train loss: 24045.47265625	(16.2s)
epoch: 76	train loss: 23878.63671875	(16.3s)
epoch: 77	train loss: 23645.978515625	(16.2s)
epoch: 78	train loss: 23799.412109375	(16.2s)
epoch: 79	train loss: 23671.068359375	(16.2s)
epoch: 80	train loss: 23741.48046875	(16.3s)
epoch: 81	train loss: 23631.2265625	(16.2s)
epoch: 82	train loss: 23549.341796875	(16.2s)
epoch: 83	train loss: 23238.646484375	(16.2s)
epoch: 84	train loss: 23320.265625	(16.2s)
epoch: 85	train loss: 24207.349609375	(16.3s)
epoch: 86	train loss: 24319.1953125	(16.2s)
epoch: 87	train loss: 23718.099609375	(16.2s)
epoch: 88	train loss: 23511.044921875	(16.2s)
epoch: 89	train loss: 23462.916015625	(16.2s)
epoch: 90	train loss: 23266.02734375	(16.2s)
epoch: 91	train loss: 23257.21484375	(16.2s)
epoch: 92	train loss: 23178.546875	(16.3s)
epoch: 93	train loss: 23204.88671875	(16.2s)
epoch: 94	train loss: 23857.271484375	(16.3s)
epoch: 95	train loss: 23003.587890625	(16.2s)
epoch: 96	train loss: 22920.4375	(16.2s)
epoch: 97	train loss: 22733.73828125	(16.3s)
epoch: 98	train loss: 23185.9296875	(16.2s)
epoch: 99	train loss: 23151.138671875	(16.2s)
Evaluating model on 200 episodes
0.0016367258758691605
0.0005911426269449294
0.0053248724434524775
0.007729617995209992
0.0022425778734032065
0.003983306582085788
0.00390907428227365
0.004011979598241548
0.0036256376188248396
0.0004038858460262418
0.0036019852850586176
0.0026027737185359
0.0046770034459768794
0.0033632447205794356
0.007962847283730904
0.005303056910634041
0.002262677939143032
0.003539995552273467
0.005367948149796575
0.0021693801099900156
0.003456431208178401
0.001266064151423052
0.007124321477022022
0.00062684909789823
0.0033765214417750635
0.0006461691518779844
0.004893710138276219
0.0040567980031482875
0.004354380187578499
0.0036665875231847167
0.0048935712984530255
0.004707088141003624
0.0009739134984556586
0.00926503847585991
0.00029351114062592387
0.009282266410688559
0.004818349261768162
0.06748462320538237
0.007367225596681237
0.005576140611083247
Solved 40/200 episodes
0.0011121964693920744
Evaluated model in 26.3 seconds
Saved model for run
e58cb3f68e74461db96fef71db8b8796 with name round-3
Round 4
Generated trajectories in 71.9 seconds
epoch: 0	train loss: 77115.9453125	(16.1s)
epoch: 1	train loss: 60976.86328125	(16.0s)
epoch: 2	train loss: 54039.7109375	(16.2s)
epoch: 3	train loss: 49819.77734375	(16.2s)
epoch: 4	train loss: 46934.296875	(16.2s)
epoch: 5	train loss: 44720.4296875	(16.2s)
epoch: 6	train loss: 42838.56640625	(16.2s)
epoch: 7	train loss: 41305.01171875	(16.2s)
epoch: 8	train loss: 40040.46484375	(16.2s)
epoch: 9	train loss: 39087.64453125	(16.2s)
epoch: 10	train loss: 37914.41796875	(16.2s)
epoch: 11	train loss: 37018.94140625	(16.2s)
epoch: 12	train loss: 36150.76171875	(16.1s)
epoch: 13	train loss: 35395.3046875	(16.2s)
epoch: 14	train loss: 34597.48828125	(16.2s)
epoch: 15	train loss: 33932.84375	(16.2s)
epoch: 16	train loss: 33545.23828125	(16.2s)
epoch: 17	train loss: 32913.81640625	(16.2s)
epoch: 18	train loss: 32676.201171875	(16.2s)
epoch: 19	train loss: 32166.900390625	(16.2s)
epoch: 20	train loss: 31399.8125	(16.1s)
epoch: 21	train loss: 30879.236328125	(16.2s)
epoch: 22	train loss: 30701.50390625	(16.2s)
epoch: 23	train loss: 30169.712890625	(16.1s)
epoch: 24	train loss: 29909.94921875	(16.1s)
epoch: 25	train loss: 29944.865234375	(16.1s)
epoch: 26	train loss: 29945.830078125	(16.2s)
epoch: 27	train loss: 29801.126953125	(16.1s)
epoch: 28	train loss: 30214.2421875	(16.1s)
epoch: 29	train loss: 29807.59375	(16.2s)
epoch: 30	train loss: 29609.791015625	(16.2s)
epoch: 31	train loss: 29255.865234375	(16.2s)
epoch: 32	train loss: 28784.052734375	(16.2s)
epoch: 33	train loss: 28307.236328125	(16.2s)
epoch: 34	train loss: 27818.078125	(16.2s)
epoch: 35	train loss: 27449.0078125	(16.2s)
epoch: 36	train loss: 27571.224609375	(16.2s)
epoch: 37	train loss: 27002.396484375	(16.2s)
epoch: 38	train loss: 26884.978515625	(16.2s)
epoch: 39	train loss: 26522.984375	(16.2s)
epoch: 40	train loss: 26373.111328125	(16.2s)
epoch: 41	train loss: 26353.064453125	(16.2s)
epoch: 42	train loss: 26047.880859375	(16.2s)
epoch: 43	train loss: 25832.052734375	(16.2s)
epoch: 44	train loss: 25420.546875	(16.2s)
epoch: 45	train loss: 25588.53125	(16.2s)
epoch: 46	train loss: 25340.146484375	(16.2s)
epoch: 47	train loss: 25400.751953125	(16.2s)
epoch: 48	train loss: 25106.38671875	(16.2s)
epoch: 49	train loss: 25031.4453125	(16.2s)
epoch: 50	train loss: 24638.916015625	(16.2s)
epoch: 51	train loss: 24489.458984375	(16.3s)
epoch: 52	train loss: 24258.283203125	(16.2s)
epoch: 53	train loss: 24315.05078125	(16.3s)
epoch: 54	train loss: 24113.07421875	(16.3s)
epoch: 55	train loss: 24777.818359375	(16.3s)
epoch: 56	train loss: 24200.583984375	(16.4s)
epoch: 57	train loss: 23666.0234375	(16.3s)
epoch: 58	train loss: 23689.189453125	(16.4s)
epoch: 59	train loss: 23708.0859375	(16.3s)
epoch: 60	train loss: 23581.7109375	(16.3s)
epoch: 61	train loss: 23675.384765625	(16.3s)
epoch: 62	train loss: 23360.560546875	(16.3s)
epoch: 63	train loss: 23215.41015625	(16.4s)
epoch: 64	train loss: 23149.455078125	(16.3s)
epoch: 65	train loss: 22958.673828125	(16.3s)
epoch: 66	train loss: 23093.771484375	(16.4s)
epoch: 67	train loss: 23336.533203125	(16.3s)
epoch: 68	train loss: 23308.7421875	(16.4s)
epoch: 69	train loss: 23226.5078125	(16.3s)
epoch: 70	train loss: 23222.923828125	(16.4s)
epoch: 71	train loss: 23009.705078125	(16.4s)
epoch: 72	train loss: 23056.44140625	(16.4s)
epoch: 73	train loss: 23032.638671875	(16.3s)
epoch: 74	train loss: 22613.552734375	(16.3s)
epoch: 75	train loss: 22467.48046875	(16.3s)
epoch: 76	train loss: 22665.08203125	(16.4s)
epoch: 77	train loss: 22792.71875	(16.3s)
epoch: 78	train loss: 22514.3125	(16.3s)
epoch: 79	train loss: 22660.224609375	(16.3s)
epoch: 80	train loss: 22880.076171875	(16.3s)
epoch: 81	train loss: 23024.486328125	(16.3s)
epoch: 82	train loss: 22986.162109375	(16.3s)
epoch: 83	train loss: 22825.435546875	(16.3s)
epoch: 84	train loss: 22527.744140625	(16.3s)
epoch: 85	train loss: 22897.365234375	(16.3s)
epoch: 86	train loss: 22711.255859375	(16.3s)
epoch: 87	train loss: 22604.796875	(16.3s)
epoch: 88	train loss: 22214.53515625	(16.3s)
epoch: 89	train loss: 22475.14453125	(16.3s)
epoch: 90	train loss: 22347.888671875	(16.3s)
epoch: 91	train loss: 22491.232421875	(16.3s)
epoch: 92	train loss: 22082.54296875	(16.3s)
epoch: 93	train loss: 21977.958984375	(16.3s)
epoch: 94	train loss: 21743.17578125	(16.3s)
epoch: 95	train loss: 21777.693359375	(16.3s)
epoch: 96	train loss: 21691.58984375	(16.3s)
epoch: 97	train loss: 22036.271484375	(16.3s)
epoch: 98	train loss: 21935.1484375	(16.3s)
epoch: 99	train loss: 22045.859375	(16.3s)
Evaluating model on 200 episodes
0.002448409446515143
0.0030508404937184728
0.0013101683871354908
0.0021057009192494056
0.002832036251978328
0.0006741177348885685
0.000799322675447911
0.000940396188525483
0.003052382671739906
0.004140694218222052
0.004433098520773153
0.005744720188279946
0.0012835559900850058
0.005498676327988505
0.0021313874749466777
0.004344718559877947
0.0025782808661460876
0.006897028365832132
0.005443111838152011
0.0013268789043650031
0.0028746454045176506
0.008601231180364266
0.00558280556773146
0.00239375741512049
0.002212890874943696
0.0037203917163424194
0.003921231371350586
0.0030828966603924832
0.0021216626628302038
0.0018727814895100892
0.0027835442451760173
0.004265671654138714
0.004558212123811245
0.005521669081645086
0.010816792828942804
0.0030480566589782634
0.0017355334421154112
0.004197076118240754
0.003409464261494577
0.003427065472351387
0.0007291750225704163
0.003611455234931782
0.0022011755499988794
0.002404067781753838
0.006190410873387009
0.0023782125984628997
0.005760272732004523
0.0008693944449381282
0.0038106602733023465
0.0030609415589424316
Solved 50/200 episodes
0.0008609933616207854
Evaluated model in 25.9 seconds
Saved model for run
e58cb3f68e74461db96fef71db8b8796 with name round-4
Round 5
Generated trajectories in 71.9 seconds
epoch: 0	train loss: 72604.140625	(16.1s)
epoch: 1	train loss: 57331.03125	(16.1s)
epoch: 2	train loss: 50701.4609375	(16.1s)
epoch: 3	train loss: 46544.4609375	(16.1s)
epoch: 4	train loss: 43497.30859375	(16.2s)
epoch: 5	train loss: 41455.18359375	(16.2s)
epoch: 6	train loss: 39548.046875	(16.2s)
epoch: 7	train loss: 38048.5390625	(16.2s)
epoch: 8	train loss: 37072.04296875	(16.2s)
epoch: 9	train loss: 36021.67578125	(16.2s)
epoch: 10	train loss: 35082.94921875	(16.2s)
epoch: 11	train loss: 34307.74609375	(16.2s)
epoch: 12	train loss: 33403.89453125	(16.2s)
epoch: 13	train loss: 33112.8515625	(16.2s)
epoch: 14	train loss: 32377.900390625	(16.2s)
epoch: 15	train loss: 31710.3046875	(16.2s)
epoch: 16	train loss: 31136.04296875	(16.2s)
epoch: 17	train loss: 30509.14453125	(16.2s)
epoch: 18	train loss: 30028.580078125	(16.2s)
epoch: 19	train loss: 29771.400390625	(16.2s)
epoch: 20	train loss: 29327.939453125	(16.2s)
epoch: 21	train loss: 29347.703125	(16.2s)
epoch: 22	train loss: 29006.7578125	(16.2s)
epoch: 23	train loss: 28588.869140625	(16.1s)
epoch: 24	train loss: 28162.095703125	(16.1s)
epoch: 25	train loss: 28147.796875	(16.1s)
epoch: 26	train loss: 27847.341796875	(16.2s)
epoch: 27	train loss: 27733.017578125	(16.2s)
epoch: 28	train loss: 27494.177734375	(16.1s)
epoch: 29	train loss: 27656.296875	(16.2s)
epoch: 30	train loss: 27672.359375	(16.3s)
epoch: 31	train loss: 27304.923828125	(16.3s)
epoch: 32	train loss: 26971.8046875	(16.2s)
epoch: 33	train loss: 26740.27734375	(16.2s)
epoch: 34	train loss: 26487.83984375	(16.2s)
epoch: 35	train loss: 26075.96484375	(16.2s)
epoch: 36	train loss: 25352.537109375	(16.2s)
epoch: 37	train loss: 25497.609375	(16.2s)
epoch: 38	train loss: 25023.486328125	(16.3s)
epoch: 39	train loss: 24737.2109375	(16.2s)
epoch: 40	train loss: 24375.55078125	(16.2s)
epoch: 41	train loss: 24267.306640625	(16.2s)
epoch: 42	train loss: 24348.447265625	(16.3s)
epoch: 43	train loss: 23976.763671875	(16.2s)
epoch: 44	train loss: 24311.259765625	(16.1s)
epoch: 45	train loss: 24932.740234375	(16.1s)
epoch: 46	train loss: 24185.314453125	(16.1s)
epoch: 47	train loss: 23779.09765625	(16.2s)
epoch: 48	train loss: 23441.5234375	(16.2s)
epoch: 49	train loss: 23722.146484375	(16.1s)
epoch: 50	train loss: 24431.744140625	(16.1s)
epoch: 51	train loss: 23489.171875	(16.2s)
epoch: 52	train loss: 23052.91796875	(16.2s)
epoch: 53	train loss: 22814.162109375	(16.2s)
epoch: 54	train loss: 22637.126953125	(16.2s)
epoch: 55	train loss: 23330.5703125	(16.1s)
epoch: 56	train loss: 22562.21875	(16.1s)
epoch: 57	train loss: 22539.763671875	(16.2s)
epoch: 58	train loss: 22951.32421875	(16.2s)
epoch: 59	train loss: 22962.927734375	(16.2s)
epoch: 60	train loss: 22957.638671875	(16.1s)
epoch: 61	train loss: 22842.09375	(16.1s)
epoch: 62	train loss: 22448.169921875	(16.2s)
epoch: 63	train loss: 22497.4765625	(16.2s)
epoch: 64	train loss: 22498.189453125	(16.1s)
epoch: 65	train loss: 22329.13671875	(16.1s)
epoch: 66	train loss: 22204.7578125	(16.1s)
epoch: 67	train loss: 22393.8515625	(16.1s)
epoch: 68	train loss: 22412.873046875	(16.2s)
epoch: 69	train loss: 22539.02734375	(16.2s)
epoch: 70	train loss: 21936.955078125	(16.1s)
epoch: 71	train loss: 22538.185546875	(16.1s)
epoch: 72	train loss: 21913.1171875	(16.1s)
epoch: 73	train loss: 22239.17578125	(16.2s)
epoch: 74	train loss: 21790.71875	(16.2s)
epoch: 75	train loss: 21695.125	(16.2s)
epoch: 76	train loss: 21638.556640625	(16.2s)
epoch: 77	train loss: 21674.283203125	(16.1s)
epoch: 78	train loss: 21681.033203125	(16.2s)
epoch: 79	train loss: 21616.9765625	(16.2s)
epoch: 80	train loss: 21499.67578125	(16.2s)
epoch: 81	train loss: 22007.873046875	(16.1s)
epoch: 82	train loss: 21640.78125	(16.1s)
epoch: 83	train loss: 21753.990234375	(16.1s)
epoch: 84	train loss: 22248.919921875	(16.2s)
epoch: 85	train loss: 21505.810546875	(16.2s)
epoch: 86	train loss: 21479.275390625	(16.1s)
epoch: 87	train loss: 20867.07421875	(16.1s)
epoch: 88	train loss: 21458.796875	(16.1s)
epoch: 89	train loss: 20917.8828125	(16.2s)
epoch: 90	train loss: 21648.68359375	(16.2s)
epoch: 91	train loss: 21406.203125	(16.2s)
epoch: 92	train loss: 21385.064453125	(16.1s)
epoch: 93	train loss: 21013.447265625	(16.1s)
epoch: 94	train loss: 20805.8828125	(16.1s)
epoch: 95	train loss: 20759.56640625	(16.2s)
epoch: 96	train loss: 20878.3984375	(16.2s)
epoch: 97	train loss: 22217.859375	(16.1s)
epoch: 98	train loss: 22290.783203125	(16.0s)
epoch: 99	train loss: 22059.55859375	(16.1s)
Evaluating model on 200 episodes
0.003770446899579838
0.006873182894196361
0.008989205554826185
0.002517128980252892
0.00339136664600422
0.0018231203430332243
0.005319222531397827
0.005805871124418142
0.002046640365733765
0.0019208570010960102
0.005710602349912127
0.003539837731902177
0.008224413366406225
0.0026263362475826093
0.002958286087960005
0.002247889875434339
0.004126961372094229
0.003654157480923459
0.001974524901015684
0.0006223271484486759
0.0017921701291925274
0.0014984026202000678
0.003761304426006973
0.00483753097942099
0.001249736223447447
0.003937248606234789
0.0024067452759481966
0.017716594234419365
0.0017483629344496876
0.002874725265428424
0.0045187683310359715
0.003835589101072401
0.0044717775817844085
0.002109748951625079
0.0678420887561515
0.004099854675587267
0.0017802155925892293
0.005947598975035362
0.0025209576851921156
0.0032270087394863367
0.011374267225619406
0.005661479201808106
0.002508602919988334
0.00322785759344697
0.0076010827130327625
0.0004706438921857625
0.005523999570868909
0.001149344607256353
0.0031194508337648585
0.0028896652802359313
0.0021910331561230123
0.004260246641933918
0.0035858675255440176
0.002269765711389482
0.004519125679507852
0.0031375683611258864
0.003442725050263107
0.006340044201351702
0.0008155705290846527
0.004043431137688458
0.0006171333589009009
0.005134427337907255
0.004989682308708628
Solved 63/200 episodes
0.0015459591141213118
Evaluated model in 23.2 seconds
Saved model for run
e58cb3f68e74461db96fef71db8b8796 with name round-5
Round 6
Generated trajectories in 72.5 seconds
epoch: 0	train loss: 67495.328125	(16.1s)
epoch: 1	train loss: 55099.97265625	(16.1s)
epoch: 2	train loss: 48645.53515625	(16.1s)
epoch: 3	train loss: 44683.421875	(16.1s)
epoch: 4	train loss: 41889.1875	(16.1s)
epoch: 5	train loss: 39762.08984375	(16.1s)
epoch: 6	train loss: 37931.078125	(16.2s)
epoch: 7	train loss: 36301.25390625	(16.2s)
epoch: 8	train loss: 35198.83984375	(16.1s)
epoch: 9	train loss: 34157.66796875	(16.1s)
epoch: 10	train loss: 33129.0703125	(16.1s)
epoch: 11	train loss: 32327.2265625	(16.2s)
epoch: 12	train loss: 31670.431640625	(16.1s)
epoch: 13	train loss: 31203.978515625	(16.2s)
epoch: 14	train loss: 30406.876953125	(16.1s)
epoch: 15	train loss: 30543.431640625	(16.1s)
epoch: 16	train loss: 29920.61328125	(16.1s)
epoch: 17	train loss: 29435.861328125	(16.2s)
epoch: 18	train loss: 29281.0703125	(16.2s)
epoch: 19	train loss: 29104.791015625	(16.1s)
epoch: 20	train loss: 28752.568359375	(16.1s)
epoch: 21	train loss: 28569.265625	(16.2s)
epoch: 22	train loss: 27681.115234375	(16.2s)
epoch: 23	train loss: 27427.107421875	(16.2s)
epoch: 24	train loss: 26746.4453125	(16.1s)
epoch: 25	train loss: 26818.095703125	(16.1s)
epoch: 26	train loss: 26243.548828125	(16.1s)
epoch: 27	train loss: 26038.6484375	(16.1s)
epoch: 28	train loss: 25698.716796875	(16.1s)
epoch: 29	train loss: 25284.53125	(16.1s)
epoch: 30	train loss: 25563.794921875	(16.1s)
epoch: 31	train loss: 25816.171875	(16.1s)
epoch: 32	train loss: 24754.052734375	(16.1s)
epoch: 33	train loss: 24511.896484375	(16.2s)
epoch: 34	train loss: 25181.525390625	(16.2s)
epoch: 35	train loss: 25385.376953125	(16.1s)
epoch: 36	train loss: 24333.322265625	(16.1s)
epoch: 37	train loss: 24106.890625	(16.1s)
epoch: 38	train loss: 23626.271484375	(16.2s)
epoch: 39	train loss: 23416.935546875	(16.2s)
epoch: 40	train loss: 23352.326171875	(16.1s)
epoch: 41	train loss: 23592.939453125	(16.1s)
epoch: 42	train loss: 23667.591796875	(16.1s)
epoch: 43	train loss: 23633.654296875	(16.2s)
epoch: 44	train loss: 23513.810546875	(16.2s)
epoch: 45	train loss: 23620.560546875	(16.1s)
epoch: 46	train loss: 23733.447265625	(16.1s)
epoch: 47	train loss: 23360.978515625	(16.1s)
epoch: 48	train loss: 23630.884765625	(16.2s)
epoch: 49	train loss: 23191.958984375	(16.2s)
epoch: 50	train loss: 22698.212890625	(16.2s)
epoch: 51	train loss: 22586.0390625	(16.1s)
epoch: 52	train loss: 24163.62890625	(16.1s)
epoch: 53	train loss: 23113.662109375	(16.2s)
epoch: 54	train loss: 22792.568359375	(16.2s)
epoch: 55	train loss: 24031.912109375	(16.2s)
epoch: 56	train loss: 22607.333984375	(16.1s)
epoch: 57	train loss: 23091.22265625	(16.1s)
epoch: 58	train loss: 22451.1484375	(16.1s)
epoch: 59	train loss: 22155.6484375	(16.1s)
epoch: 60	train loss: 22752.501953125	(16.2s)
epoch: 61	train loss: 22586.359375	(16.1s)
epoch: 62	train loss: 22420.826171875	(16.1s)
epoch: 63	train loss: 22143.884765625	(16.1s)
epoch: 64	train loss: 21829.982421875	(16.2s)
epoch: 65	train loss: 21925.048828125	(16.2s)
epoch: 66	train loss: 21557.82421875	(16.1s)
epoch: 67	train loss: 22315.298828125	(16.1s)
epoch: 68	train loss: 22193.705078125	(16.1s)
epoch: 69	train loss: 22031.21484375	(16.2s)
epoch: 70	train loss: 21678.71484375	(16.2s)
epoch: 71	train loss: 21906.58984375	(16.2s)
epoch: 72	train loss: 21715.861328125	(16.2s)
epoch: 73	train loss: 21810.724609375	(16.1s)
epoch: 74	train loss: 21696.982421875	(16.2s)
epoch: 75	train loss: 22198.986328125	(16.2s)
epoch: 76	train loss: 22220.23828125	(16.2s)
epoch: 77	train loss: 21947.505859375	(16.1s)
epoch: 78	train loss: 21490.580078125	(16.1s)
epoch: 79	train loss: 21472.4765625	(16.2s)
epoch: 80	train loss: 21426.99609375	(16.2s)
epoch: 81	train loss: 21318.134765625	(16.2s)
epoch: 82	train loss: 21719.482421875	(16.1s)
epoch: 83	train loss: 22128.0078125	(16.1s)
epoch: 84	train loss: 21322.48046875	(16.2s)
epoch: 85	train loss: 21317.6640625	(16.2s)
epoch: 86	train loss: 21362.591796875	(16.2s)
epoch: 87	train loss: 21907.52734375	(16.2s)
epoch: 88	train loss: 21830.021484375	(16.1s)
epoch: 89	train loss: 21532.525390625	(16.1s)
epoch: 90	train loss: 21439.4296875	(16.2s)
epoch: 91	train loss: 21884.1484375	(16.2s)
epoch: 92	train loss: 21492.74609375	(16.2s)
epoch: 93	train loss: 21091.3359375	(16.2s)
epoch: 94	train loss: 21291.630859375	(16.1s)
epoch: 95	train loss: 21246.2734375	(16.2s)
epoch: 96	train loss: 22066.69921875	(16.1s)
epoch: 97	train loss: 21598.09765625	(16.2s)
epoch: 98	train loss: 21120.671875	(16.1s)
epoch: 99	train loss: 21459.61328125	(16.0s)
Evaluating model on 200 episodes
0.002406032154491792
0.005815705819986761
0.005849910938801865
0.006024756468832493
0.0029338372696656734
0.009554786141961813
0.0044536129862535745
0.002926108063547872
0.005008147447369993
0.002841713256202638
0.006293750775512308
0.009300805220846087
0.010777540737763047
0.005324719473719597
0.00441525864880532
0.003724412905285135
0.0024724486574996263
0.003069273487199098
0.003934094565920532
0.0038645035917094597
0.004075467775692232
0.005124529804258297
0.0047281280159950255
0.006604132344364189
0.0011395759647712111
0.004231603629887104
0.010435319971293211
0.004410237073898315
0.0017682051984593272
0.0029661597994466624
0.0023525443975813687
0.0019329289207234979
0.0048108982349125045
0.008148113789502531
0.004037538543343544
0.0034575366880744696
0.0007695254462305456
0.0073434337294505285
0.008057954721152782
0.0013773777172900736
0.005798885831609368
0.004595716236508451
0.002803152281558141
0.0022593064641114324
0.006144726105655233
0.006243511607560019
0.0029215566270674267
0.09054741372043888
0.003981213201768696
0.002822641545208171
0.010892737147514708
0.0034232228451098004
0.003616559028159827
0.003645331171962122
0.003836567630060017
0.004803415155038238
0.002085244554715852
0.00375879129084448
0.005342466349247843
0.006793038919568062
0.0029624013550346717
0.002875752979889512
0.003877862123772502
0.003039552907769879
0.00317058979999274
0.003209055314073339
0.0016080393106676638
0.005809424168546684
0.0038807884557172656
0.0015339595265686512
0.0058962963812518865
0.005304703314322978
0.005005814261191214
0.0020034100161865354
0.004499270173255354
0.0037151701108086854
0.0030798226362094283
0.0025785939069464803
0.0036116759680832424
0.0024474029196426272
0.00589069863781333
0.00381379520210127
0.003853068958657483
0.0033955731196328998
0.0036939119454473257
0.004210256767692044
0.0022537718759849668
Solved 87/200 episodes
0.002311493951143348
Evaluated model in 19.9 seconds
Saved model for run
e58cb3f68e74461db96fef71db8b8796 with name round-6
Round 7
Generated trajectories in 72.6 seconds
epoch: 0	train loss: 66926.6875	(16.3s)
epoch: 1	train loss: 54273.76171875	(16.3s)
epoch: 2	train loss: 48009.41796875	(16.5s)
epoch: 3	train loss: 43985.76953125	(16.5s)
epoch: 4	train loss: 40986.06640625	(16.5s)
epoch: 5	train loss: 38970.8203125	(16.4s)
epoch: 6	train loss: 37432.19140625	(16.4s)
epoch: 7	train loss: 36604.578125	(16.5s)
epoch: 8	train loss: 34876.6640625	(16.5s)
epoch: 9	train loss: 34183.6640625	(16.5s)
epoch: 10	train loss: 33394.59375	(16.4s)
epoch: 11	train loss: 32895.33203125	(16.4s)
epoch: 12	train loss: 32436.541015625	(16.5s)
epoch: 13	train loss: 31749.353515625	(16.5s)
epoch: 14	train loss: 31329.845703125	(16.5s)
epoch: 15	train loss: 31486.099609375	(16.5s)
epoch: 16	train loss: 30542.74609375	(16.4s)
epoch: 17	train loss: 29675.439453125	(16.5s)
epoch: 18	train loss: 29284.935546875	(16.5s)
epoch: 19	train loss: 28577.45703125	(16.5s)
epoch: 20	train loss: 28959.623046875	(16.5s)
epoch: 21	train loss: 28294.69921875	(16.4s)
epoch: 22	train loss: 28063.9375	(16.5s)
epoch: 23	train loss: 27445.296875	(16.5s)
epoch: 24	train loss: 28143.17578125	(16.5s)
epoch: 25	train loss: 30037.400390625	(16.5s)
epoch: 26	train loss: 28163.390625	(16.4s)
epoch: 27	train loss: 28018.28125	(16.4s)
epoch: 28	train loss: 27317.796875	(16.4s)
epoch: 29	train loss: 27081.298828125	(16.4s)
epoch: 30	train loss: 26757.689453125	(16.4s)
epoch: 31	train loss: 26334.59765625	(16.4s)
epoch: 32	train loss: 25918.94140625	(16.4s)
epoch: 33	train loss: 25990.37890625	(16.5s)
epoch: 34	train loss: 25737.86328125	(16.5s)
epoch: 35	train loss: 25723.787109375	(16.5s)
epoch: 36	train loss: 25550.494140625	(16.4s)
epoch: 37	train loss: 25994.572265625	(16.5s)
epoch: 38	train loss: 25721.873046875	(16.5s)
epoch: 39	train loss: 25809.9609375	(16.5s)
epoch: 40	train loss: 25652.5703125	(16.5s)
epoch: 41	train loss: 24953.466796875	(16.4s)
epoch: 42	train loss: 24890.90234375	(16.5s)
epoch: 43	train loss: 24669.859375	(16.5s)
epoch: 44	train loss: 24413.482421875	(16.5s)
epoch: 45	train loss: 24537.78125	(16.5s)
epoch: 46	train loss: 24419.408203125	(16.5s)
epoch: 47	train loss: 24612.87109375	(16.5s)
epoch: 48	train loss: 24402.69140625	(16.5s)
epoch: 49	train loss: 24451.916015625	(16.5s)
epoch: 50	train loss: 24198.560546875	(16.5s)
epoch: 51	train loss: 24824.900390625	(16.5s)
epoch: 52	train loss: 24217.419921875	(16.5s)
epoch: 53	train loss: 23789.458984375	(16.5s)
epoch: 54	train loss: 23243.09375	(16.5s)
epoch: 55	train loss: 23610.025390625	(16.5s)
epoch: 56	train loss: 25072.9296875	(16.5s)
epoch: 57	train loss: 23937.236328125	(16.5s)
epoch: 58	train loss: 23795.75390625	(16.5s)
epoch: 59	train loss: 24389.0625	(16.5s)
epoch: 60	train loss: 23182.349609375	(16.5s)
epoch: 61	train loss: 23083.810546875	(16.5s)
epoch: 62	train loss: 23535.724609375	(16.5s)
epoch: 63	train loss: 23475.462890625	(16.4s)
epoch: 64	train loss: 23466.14453125	(16.5s)
epoch: 65	train loss: 22784.046875	(16.5s)
epoch: 66	train loss: 22360.9375	(16.5s)
epoch: 67	train loss: 22226.337890625	(16.4s)
epoch: 68	train loss: 22704.9921875	(16.5s)
epoch: 69	train loss: 22874.5859375	(16.5s)
epoch: 70	train loss: 24216.423828125	(16.5s)
epoch: 71	train loss: 25300.908203125	(16.5s)
epoch: 72	train loss: 23275.55859375	(16.5s)
epoch: 73	train loss: 22878.5625	(16.4s)
epoch: 74	train loss: 22745.142578125	(16.5s)
epoch: 75	train loss: 22434.009765625	(16.5s)
epoch: 76	train loss: 21874.69140625	(16.5s)
epoch: 77	train loss: 22216.7265625	(16.5s)
epoch: 78	train loss: 22489.53125	(16.5s)
epoch: 79	train loss: 23382.8671875	(16.5s)
epoch: 80	train loss: 23250.84375	(16.5s)
epoch: 81	train loss: 22126.791015625	(16.6s)
epoch: 82	train loss: 23117.96875	(16.6s)
epoch: 83	train loss: 22453.666015625	(16.5s)
epoch: 84	train loss: 21925.791015625	(16.5s)
epoch: 85	train loss: 21745.25390625	(16.5s)
epoch: 86	train loss: 21985.75	(16.6s)
epoch: 87	train loss: 24089.845703125	(16.5s)
epoch: 88	train loss: 23015.16015625	(16.5s)
epoch: 89	train loss: 22058.607421875	(16.5s)
epoch: 90	train loss: 24293.935546875	(16.5s)
epoch: 91	train loss: 23343.23828125	(16.5s)
epoch: 92	train loss: 22127.85546875	(16.5s)
epoch: 93	train loss: 21857.3203125	(16.4s)
epoch: 94	train loss: 21647.146484375	(16.4s)
epoch: 95	train loss: 21860.1171875	(16.5s)
epoch: 96	train loss: 21827.609375	(16.5s)
epoch: 97	train loss: 21805.765625	(16.5s)
epoch: 98	train loss: 21469.8203125	(16.4s)
epoch: 99	train loss: 21312.517578125	(16.4s)
Evaluating model on 200 episodes
0.0035504119781156382
0.001610832172445953
0.0038576409220695495
0.006623005756409839
0.004415986419189721
0.004245301667833701
0.0034102839999832213
0.006014396523823962
0.003054697997868061
0.004844170901924372
0.0013909734261687845
0.004459305811906233
0.003714209742611274
0.0005360156937967986
0.003971690234417717
0.004231254560484861
0.0013481908245012164
0.0011043077829526737
0.005128949162705491
0.0027794755587819964
0.0040246998056924594
0.0031552353175356984
0.007282429549377412
0.0033498287200927736
0.005767012160504237
0.002124736551195383
0.0024076893751043826
0.007020368182566017
0.004557971842586994
0.0059919305494986475
0.004250998608767986
0.002057490055449307
0.003731480101123452
0.0028288758559418575
0.0030821323016425595
0.004441957920789719
0.0041812626489748555
0.004742610256653279
0.003931941057089716
0.003548597829649225
0.002481506351614371
0.00448471654090099
0.0046319848236938315
0.0032641260186210275
0.007264145688774685
0.002856884675566107
0.003983987960964441
0.0039740859841307
0.003155575851754596
0.0027332182362442836
0.010197635546016196
0.0013730829814448953
0.003916743047739146
0.0037984431255608797
0.0040483078531300025
0.0031224770937114954
0.0034788392561798296
0.0031251478649210185
0.003737142193131149
0.005957983434200287
0.005202220584033057
0.005566940177232027
0.0035710956508410163
0.006405713479034602
0.00503533900094529
0.003993991587776691
0.0030885985082325837
0.005745344577007927
0.0031044117640703917
0.0027069050508240857
0.0036623209404448667
0.0034984031808562577
0.005119793931953609
0.004179563373327255
0.0026297969379811548
0.003672256926074624
0.0037212906288914384
0.004015884449472651
0.0029474182229023427
0.005007222294807434
0.0027832851410494186
0.0033773727482184768
0.004800812748726457
0.0017869487637653947
0.0034519408945925534
0.005998810675616066
0.004247439093887806
Solved 87/200 episodes
0.0017183875284454626
Evaluated model in 21.4 seconds
Saved model for run
e58cb3f68e74461db96fef71db8b8796 with name round-7
Round 8
Generated trajectories in 72.9 seconds
epoch: 0	train loss: 59188.78125	(16.4s)
epoch: 1	train loss: 49015.0	(16.2s)
epoch: 2	train loss: 43609.42578125	(16.4s)
epoch: 3	train loss: 40536.20703125	(16.4s)
epoch: 4	train loss: 38100.2265625	(16.4s)
epoch: 5	train loss: 36569.6171875	(16.4s)
epoch: 6	train loss: 35076.01953125	(16.4s)
epoch: 7	train loss: 34096.62890625	(16.4s)
epoch: 8	train loss: 32892.52734375	(16.5s)
epoch: 9	train loss: 32770.2109375	(16.5s)
epoch: 10	train loss: 31835.626953125	(16.4s)
epoch: 11	train loss: 31211.4140625	(16.5s)
epoch: 12	train loss: 30989.015625	(16.4s)
epoch: 13	train loss: 31016.423828125	(16.5s)
epoch: 14	train loss: 30260.052734375	(16.4s)
epoch: 15	train loss: 30903.685546875	(16.5s)
epoch: 16	train loss: 29669.3515625	(16.4s)
epoch: 17	train loss: 28898.244140625	(16.5s)
epoch: 18	train loss: 28640.73828125	(16.4s)
epoch: 19	train loss: 28325.705078125	(16.4s)
epoch: 20	train loss: 28629.1875	(16.4s)
epoch: 21	train loss: 28232.595703125	(16.4s)
epoch: 22	train loss: 27710.517578125	(16.4s)
epoch: 23	train loss: 28240.83203125	(16.4s)
epoch: 24	train loss: 28093.294921875	(16.5s)
epoch: 25	train loss: 27371.89453125	(16.5s)
epoch: 26	train loss: 27067.375	(16.5s)
epoch: 27	train loss: 26984.123046875	(16.4s)
epoch: 28	train loss: 26778.822265625	(16.5s)
epoch: 29	train loss: 26505.28125	(16.5s)
epoch: 30	train loss: 26189.57421875	(16.4s)
epoch: 31	train loss: 25766.37109375	(16.4s)
epoch: 32	train loss: 25652.783203125	(16.4s)
epoch: 33	train loss: 25404.3203125	(16.4s)
epoch: 34	train loss: 25459.1953125	(16.5s)
epoch: 35	train loss: 27875.2734375	(16.4s)
epoch: 36	train loss: 26293.505859375	(16.4s)
epoch: 37	train loss: 25858.265625	(16.4s)
epoch: 38	train loss: 25772.1640625	(16.4s)
epoch: 39	train loss: 25479.158203125	(16.5s)
epoch: 40	train loss: 24686.271484375	(16.4s)
epoch: 41	train loss: 24511.126953125	(16.5s)
epoch: 42	train loss: 24247.05078125	(16.4s)
epoch: 43	train loss: 24148.734375	(16.4s)
epoch: 44	train loss: 24155.8125	(16.4s)
epoch: 45	train loss: 24496.888671875	(16.4s)
epoch: 46	train loss: 24265.64453125	(16.4s)
epoch: 47	train loss: 24498.337890625	(16.4s)
epoch: 48	train loss: 23946.041015625	(16.4s)
epoch: 49	train loss: 24467.73828125	(16.4s)
epoch: 50	train loss: 24564.169921875	(16.5s)
epoch: 51	train loss: 24355.466796875	(16.5s)
epoch: 52	train loss: 24229.2109375	(16.4s)
epoch: 53	train loss: 24036.65625	(16.4s)
epoch: 54	train loss: 23672.48046875	(16.4s)
epoch: 55	train loss: 24796.595703125	(16.4s)
epoch: 56	train loss: 25296.759765625	(16.4s)
epoch: 57	train loss: 24248.849609375	(16.4s)
epoch: 58	train loss: 24602.8359375	(16.4s)
epoch: 59	train loss: 25215.537109375	(16.4s)
epoch: 60	train loss: 24295.40625	(16.4s)
epoch: 61	train loss: 24259.70703125	(16.4s)
epoch: 62	train loss: 23318.16796875	(16.4s)
epoch: 63	train loss: 22885.474609375	(16.4s)
epoch: 64	train loss: 22849.841796875	(16.4s)
epoch: 65	train loss: 22927.443359375	(16.4s)
epoch: 66	train loss: 23198.90625	(16.4s)
epoch: 67	train loss: 23119.41015625	(16.4s)
epoch: 68	train loss: 22863.294921875	(16.4s)
epoch: 69	train loss: 22737.900390625	(16.4s)
epoch: 70	train loss: 22944.421875	(16.4s)
epoch: 71	train loss: 23105.5	(16.5s)
epoch: 72	train loss: 22970.099609375	(16.4s)
epoch: 73	train loss: 22498.1484375	(16.4s)
epoch: 74	train loss: 23270.30078125	(16.4s)
epoch: 75	train loss: 24100.193359375	(16.4s)
epoch: 76	train loss: 23134.794921875	(16.4s)
epoch: 77	train loss: 22771.046875	(16.4s)
epoch: 78	train loss: 24082.078125	(16.4s)
epoch: 79	train loss: 22970.716796875	(16.4s)
epoch: 80	train loss: 22947.69140625	(16.4s)
epoch: 81	train loss: 22313.44921875	(16.4s)
epoch: 82	train loss: 22100.625	(16.4s)
epoch: 83	train loss: 22121.494140625	(16.4s)
epoch: 84	train loss: 22949.30078125	(16.4s)
epoch: 85	train loss: 22600.310546875	(16.4s)
epoch: 86	train loss: 22167.357421875	(16.4s)
epoch: 87	train loss: 22070.609375	(16.4s)
epoch: 88	train loss: 25044.9921875	(16.5s)
epoch: 89	train loss: 26922.912109375	(16.4s)
epoch: 90	train loss: 24266.193359375	(16.4s)
epoch: 91	train loss: 22892.525390625	(16.4s)
epoch: 92	train loss: 22329.607421875	(16.4s)
epoch: 93	train loss: 22484.58203125	(16.4s)
epoch: 94	train loss: 22650.10546875	(16.4s)
epoch: 95	train loss: 23090.33203125	(16.4s)
epoch: 96	train loss: 22294.720703125	(16.4s)
epoch: 97	train loss: 22412.173828125	(16.4s)
epoch: 98	train loss: 22242.61328125	(16.4s)
epoch: 99	train loss: 22426.794921875	(16.3s)
Evaluating model on 200 episodes
0.002870810800231993
0.08588613466417883
0.006172618502750993
0.002702764541027136
0.002166789510132124
0.003910472810578843
0.006137132993899286
0.004697433032561094
0.0039044906152412295
0.0017697731091175228
0.005360635899705812
0.004769799939822406
0.003909970323244731
0.004399771763322254
0.0045005619060248135
0.004848712525563315
0.0010569571168161929
0.003968148414666454
0.0038173985230969265
0.003383927120012231
0.004039334962726571
0.0033842995180748403
0.003033888613572344
0.0035567544788743057
0.0016627705772407353
0.001205230044433847
0.0012795876245945692
0.003063953365199268
0.003644199125119485
0.003939463567803614
0.004999377531930804
0.013174505205824971
0.0034638889968240014
0.003982414666097611
0.002233156279544346
0.0034357049407844897
0.002784508280456066
0.0026212824595859274
0.005328320781700313
0.00354031475338464
0.004148799809627235
0.007103936721250648
0.011924322170671076
0.002059723366983235
0.005301926983520389
0.0023817095207050443
0.005606169841485098
0.004384106840007007
0.0037067217247871063
0.0052842956404977786
0.004131536674685776
0.0035313956905156374
0.002782733179628849
0.0029342380294110626
0.0032526242705768838
0.0030448221950791776
0.004027136019431055
0.0016301076393574476
0.003128912421137405
0.0037831158260814846
0.0041121307100790245
0.006208972384532292
0.002431146946037188
0.0034380718043394154
0.008275438682176173
0.009391956419373551
0.0038010592106729746
0.006429101646062918
0.00376043317373842
0.0038918924207488694
0.010085326211992651
0.00297377270180732
0.004663323217149203
0.0037575768656097353
0.002395920208073221
0.004894381905614864
0.007173531921580434
0.0036163743570796214
0.004982579818170052
0.004249743709806353
0.003711002073638762
0.0031596648429209986
0.004412645163635413
0.005241195589769631
0.003201908868504688
0.004241008893586695
0.0048315640015061945
0.0029002996161580086
0.005090945097617805
0.0025209614541381598
0.0022578554780920967
0.005395050422521308
0.006164354854263365
0.003795827622525394
0.003935019136406481
0.0019856984581565484
0.00324999654549174
0.00531764995927612
0.0021065318724140525
0.003103840572293848
Solved 100/200 episodes
0.00247955674644384
Evaluated model in 22.4 seconds
Saved model for run
e58cb3f68e74461db96fef71db8b8796 with name round-8
Round 9
Generated trajectories in 72.9 seconds
epoch: 0	train loss: 54840.26171875	(16.3s)
epoch: 1	train loss: 45733.4609375	(16.3s)
epoch: 2	train loss: 40815.46875	(16.3s)
epoch: 3	train loss: 38145.46484375	(16.5s)
epoch: 4	train loss: 36304.8359375	(16.5s)
epoch: 5	train loss: 34644.078125	(16.5s)
epoch: 6	train loss: 34112.62890625	(16.4s)
epoch: 7	train loss: 33550.359375	(16.4s)
epoch: 8	train loss: 32179.001953125	(16.5s)
epoch: 9	train loss: 31568.58984375	(16.5s)
epoch: 10	train loss: 31158.04296875	(16.5s)
epoch: 11	train loss: 30429.193359375	(16.4s)
epoch: 12	train loss: 29968.236328125	(16.4s)
epoch: 13	train loss: 29425.41015625	(16.5s)
epoch: 14	train loss: 29289.2109375	(16.5s)
epoch: 15	train loss: 28820.2109375	(16.5s)
epoch: 16	train loss: 28442.81640625	(16.4s)
epoch: 17	train loss: 28252.03515625	(16.4s)
epoch: 18	train loss: 27709.8515625	(16.5s)
epoch: 19	train loss: 27679.7421875	(16.5s)
epoch: 20	train loss: 27265.962890625	(16.5s)
epoch: 21	train loss: 28277.54296875	(16.4s)
epoch: 22	train loss: 27543.701171875	(16.4s)
epoch: 23	train loss: 26848.78515625	(16.5s)
epoch: 24	train loss: 26620.0	(16.5s)
epoch: 25	train loss: 27544.982421875	(16.5s)
epoch: 26	train loss: 27001.60546875	(16.4s)
epoch: 27	train loss: 26392.703125	(16.3s)
epoch: 28	train loss: 26394.9921875	(16.3s)
epoch: 29	train loss: 25867.212890625	(16.5s)
epoch: 30	train loss: 25551.66015625	(16.5s)
epoch: 31	train loss: 25906.99609375	(16.5s)
epoch: 32	train loss: 25662.56640625	(16.4s)
epoch: 33	train loss: 25266.25	(16.4s)
epoch: 34	train loss: 25267.45703125	(16.5s)
epoch: 35	train loss: 25362.619140625	(16.5s)
epoch: 36	train loss: 27319.126953125	(16.5s)
epoch: 37	train loss: 26025.77734375	(16.5s)
epoch: 38	train loss: 25367.1640625	(16.5s)
epoch: 39	train loss: 25504.328125	(16.5s)
epoch: 40	train loss: 24575.4296875	(16.5s)
epoch: 41	train loss: 24631.705078125	(16.5s)
epoch: 42	train loss: 26222.0	(16.4s)
epoch: 43	train loss: 24864.3984375	(16.4s)
epoch: 44	train loss: 24710.408203125	(16.5s)
epoch: 45	train loss: 24179.658203125	(16.5s)
epoch: 46	train loss: 24155.728515625	(16.5s)
epoch: 47	train loss: 23994.521484375	(16.4s)
epoch: 48	train loss: 23801.923828125	(16.4s)
epoch: 49	train loss: 23951.34375	(16.5s)
epoch: 50	train loss: 23506.66796875	(16.5s)
epoch: 51	train loss: 23475.3203125	(16.5s)
epoch: 52	train loss: 23881.0546875	(16.5s)
epoch: 53	train loss: 24961.982421875	(16.4s)
epoch: 54	train loss: 25200.3671875	(16.3s)
epoch: 55	train loss: 24204.43359375	(16.5s)
epoch: 56	train loss: 23675.806640625	(16.5s)
epoch: 57	train loss: 23484.669921875	(16.5s)
epoch: 58	train loss: 23281.79296875	(16.4s)
epoch: 59	train loss: 23036.38671875	(16.4s)
epoch: 60	train loss: 23284.888671875	(16.5s)
epoch: 61	train loss: 24409.517578125	(16.5s)
epoch: 62	train loss: 23904.517578125	(16.5s)
epoch: 63	train loss: 23094.68359375	(16.4s)
epoch: 64	train loss: 22990.458984375	(16.4s)
epoch: 65	train loss: 22625.306640625	(16.4s)
epoch: 66	train loss: 22831.96875	(16.4s)
epoch: 67	train loss: 25008.5078125	(16.5s)
epoch: 68	train loss: 24395.58984375	(16.4s)
epoch: 69	train loss: 23971.06640625	(16.4s)
epoch: 70	train loss: 22965.900390625	(16.5s)
epoch: 71	train loss: 22876.572265625	(16.5s)
epoch: 72	train loss: 22674.62109375	(16.5s)
epoch: 73	train loss: 22505.587890625	(16.4s)
epoch: 74	train loss: 27928.20703125	(16.4s)
epoch: 75	train loss: 24834.6015625	(16.3s)
epoch: 76	train loss: 23394.28125	(16.5s)
epoch: 77	train loss: 22615.70703125	(16.5s)
epoch: 78	train loss: 22092.49609375	(16.5s)
epoch: 79	train loss: 21929.59375	(16.4s)
epoch: 80	train loss: 22287.76953125	(16.5s)
epoch: 81	train loss: 22440.263671875	(16.5s)
epoch: 82	train loss: 22214.306640625	(16.5s)
epoch: 83	train loss: 22406.740234375	(16.5s)
epoch: 84	train loss: 23331.447265625	(16.4s)
epoch: 85	train loss: 23286.681640625	(16.4s)
epoch: 86	train loss: 23611.572265625	(16.5s)
epoch: 87	train loss: 23336.66015625	(16.5s)
epoch: 88	train loss: 22151.66796875	(16.5s)
epoch: 89	train loss: 22092.22265625	(16.4s)
epoch: 90	train loss: 21889.841796875	(16.5s)
epoch: 91	train loss: 22036.84765625	(16.5s)
epoch: 92	train loss: 22235.671875	(16.5s)
epoch: 93	train loss: 23261.8359375	(16.5s)
epoch: 94	train loss: 23505.66015625	(16.4s)
epoch: 95	train loss: 22280.453125	(16.4s)
epoch: 96	train loss: 22434.08984375	(16.5s)
epoch: 97	train loss: 22418.435546875	(16.4s)
epoch: 98	train loss: 22158.35546875	(16.4s)
epoch: 99	train loss: 21577.26171875	(16.4s)
Evaluating model on 200 episodes
0.004017059730055432
0.005465183562288682
0.006243479248951189
0.006022331246640533
0.005049034817299495
0.0031120729399845004
0.0036326097597338958
0.004082422470673919
0.005426409828942269
0.007784219320456032
0.00715875718742609
0.006651279021752998
0.0017642927268752828
0.003826972524014612
0.0024766851274762303
0.003201914601959288
0.0020351738882406303
0.0037578894989565015
0.0123124715173617
0.004696717136539519
0.0020951072219759226
0.005112245387863368
0.00720328907482326
0.008117369055980816
0.008150135516189039
0.0021499983267858624
0.004516485593436907
0.012505499801288048
0.004933660966344178
0.006465179056249326
0.003398073992381493
0.005352467531338334
0.0041295732371509075
0.006343376681408179
0.005089501787248689
0.002417208335828036
0.0052499285084195435
0.0035233979773086808
0.009241020980490637
0.0027180165561730973
0.003180218938117226
0.006372340455917376
0.0034991520224139094
0.003246526912941287
0.002770167397102341
0.001375066873151809
0.005293219893549879
0.0029824684218813977
0.0029322364134714007
0.001979992550332099
0.005804671401468416
0.004049320355989039
0.0022307048396517835
0.0028117953334003687
0.0035894454728501537
0.0036247033858671784
0.003899238877541696
0.0032022657978814095
0.0055797979002818465
0.005488320661243051
0.0032071181728194156
0.007546793227083981
0.005230957205640152
0.005208916962146759
0.004336244834121317
0.0037533987837377937
0.007527088571805507
0.003084221272729337
0.004592010925989598
0.004777224315330386
0.005211382541650285
0.0023621900618309155
0.002130361332092434
0.002336610486963764
0.0017080135294236243
0.002033389813732356
0.005867157189641148
0.005776760567511831
0.0023395251482725143
0.003630941908340901
0.0023764553479850292
0.0024048566507796445
0.009408115392683871
0.0038458616860831776
0.008220536913722754
0.002205824595876038
0.006486466620117426
0.008050801348872483
0.001293426981040587
0.003372608897431443
0.0028364102472551167
0.009373582475139605
0.0022791948285885155
0.003274043105193414
0.005221714711903284
0.002060850461324056
0.004231025183495755
0.0031579952919855714
0.006313082948327065
0.006705171239445917
0.001993156911339611
0.001300687959883362
0.0024073180411505746
0.005807478704290199
0.027384704939322546
0.0028152361628599465
0.003393866855185479
Solved 107/200 episodes
0.0025111047350075666
Evaluated model in 25.0 seconds
Saved model for run
e58cb3f68e74461db96fef71db8b8796 with name round-9
Round 10
Generated trajectories in 72.9 seconds
epoch: 0	train loss: 53101.19140625	(16.2s)
epoch: 1	train loss: 43907.71875	(16.2s)
epoch: 2	train loss: 39369.6953125	(16.2s)
epoch: 3	train loss: 36935.01953125	(16.2s)
epoch: 4	train loss: 34804.625	(16.2s)
epoch: 5	train loss: 33468.87890625	(16.3s)
epoch: 6	train loss: 32900.66796875	(16.2s)
epoch: 7	train loss: 31971.759765625	(16.2s)
epoch: 8	train loss: 31299.78125	(16.2s)
epoch: 9	train loss: 30719.55859375	(16.3s)
epoch: 10	train loss: 30601.91796875	(16.3s)
epoch: 11	train loss: 30332.5234375	(16.2s)
epoch: 12	train loss: 29658.939453125	(16.2s)
epoch: 13	train loss: 29155.677734375	(16.3s)
epoch: 14	train loss: 28566.74609375	(16.3s)
epoch: 15	train loss: 28136.556640625	(16.3s)
epoch: 16	train loss: 27944.13671875	(16.2s)
epoch: 17	train loss: 28696.11328125	(16.2s)
epoch: 18	train loss: 28181.810546875	(16.2s)
epoch: 19	train loss: 27094.830078125	(16.3s)
epoch: 20	train loss: 28267.095703125	(16.3s)
epoch: 21	train loss: 26992.00390625	(16.2s)
epoch: 22	train loss: 26640.123046875	(16.2s)
epoch: 23	train loss: 26468.130859375	(16.2s)
epoch: 24	train loss: 26333.869140625	(16.3s)
epoch: 25	train loss: 26459.47265625	(16.3s)
epoch: 26	train loss: 26174.85546875	(16.3s)
epoch: 27	train loss: 26245.806640625	(16.2s)
epoch: 28	train loss: 25713.00390625	(16.2s)
epoch: 29	train loss: 25683.759765625	(16.2s)
epoch: 30	train loss: 25191.693359375	(16.2s)
epoch: 31	train loss: 25017.76171875	(16.2s)
epoch: 32	train loss: 25334.849609375	(16.2s)
epoch: 33	train loss: 25244.3828125	(16.2s)
epoch: 34	train loss: 25086.443359375	(16.2s)
epoch: 35	train loss: 26067.951171875	(16.3s)
epoch: 36	train loss: 25477.4609375	(16.3s)
epoch: 37	train loss: 24902.51171875	(16.2s)
epoch: 38	train loss: 24820.029296875	(16.2s)
epoch: 39	train loss: 25098.7734375	(16.3s)
epoch: 40	train loss: 24461.291015625	(16.3s)
epoch: 41	train loss: 24443.099609375	(16.3s)
epoch: 42	train loss: 24474.845703125	(16.3s)
epoch: 43	train loss: 24447.86328125	(16.2s)
epoch: 44	train loss: 24065.62890625	(16.2s)
epoch: 45	train loss: 24503.98046875	(16.3s)
epoch: 46	train loss: 24164.353515625	(16.3s)
epoch: 47	train loss: 26048.931640625	(16.3s)
epoch: 48	train loss: 24837.744140625	(16.2s)
epoch: 49	train loss: 24518.603515625	(16.2s)
epoch: 50	train loss: 23884.72265625	(16.2s)
epoch: 51	train loss: 23547.76171875	(16.3s)
epoch: 52	train loss: 23448.384765625	(16.3s)
epoch: 53	train loss: 23824.525390625	(16.2s)
epoch: 54	train loss: 23525.98046875	(16.2s)
epoch: 55	train loss: 23115.87109375	(16.2s)
epoch: 56	train loss: 23036.291015625	(16.3s)
epoch: 57	train loss: 22975.95703125	(16.3s)
epoch: 58	train loss: 23058.197265625	(16.2s)
epoch: 59	train loss: 23364.21875	(16.2s)
epoch: 60	train loss: 23378.185546875	(16.2s)
epoch: 61	train loss: 23978.9921875	(16.3s)
epoch: 62	train loss: 23598.990234375	(16.3s)
epoch: 63	train loss: 24691.490234375	(16.2s)
epoch: 64	train loss: 23792.48828125	(16.2s)
epoch: 65	train loss: 22887.28515625	(16.2s)
epoch: 66	train loss: 22874.103515625	(16.3s)
epoch: 67	train loss: 22752.7734375	(16.2s)
epoch: 68	train loss: 23060.85546875	(16.3s)
epoch: 69	train loss: 24325.55078125	(16.2s)
epoch: 70	train loss: 24895.78125	(16.2s)
epoch: 71	train loss: 23456.599609375	(16.2s)
epoch: 72	train loss: 23550.140625	(16.3s)
epoch: 73	train loss: 22898.705078125	(16.3s)
epoch: 74	train loss: 23363.17578125	(16.2s)
epoch: 75	train loss: 23530.0390625	(16.2s)
epoch: 76	train loss: 23601.0234375	(16.2s)
epoch: 77	train loss: 22833.490234375	(16.3s)
epoch: 78	train loss: 22675.40625	(16.3s)
epoch: 79	train loss: 23131.595703125	(16.2s)
epoch: 80	train loss: 23282.509765625	(16.2s)
epoch: 81	train loss: 23773.78125	(16.2s)
epoch: 82	train loss: 22707.60546875	(16.2s)
epoch: 83	train loss: 22285.28515625	(16.3s)
epoch: 84	train loss: 22198.3046875	(16.3s)
epoch: 85	train loss: 22467.705078125	(16.2s)
epoch: 86	train loss: 22179.88671875	(16.2s)
epoch: 87	train loss: 23075.8046875	(16.3s)
epoch: 88	train loss: 23645.904296875	(16.3s)
epoch: 89	train loss: 23508.92578125	(16.3s)
epoch: 90	train loss: 22945.9609375	(16.2s)
epoch: 91	train loss: 22341.25390625	(16.2s)
epoch: 92	train loss: 22099.08203125	(16.2s)
epoch: 93	train loss: 22125.25	(16.3s)
epoch: 94	train loss: 22045.48828125	(16.3s)
epoch: 95	train loss: 21973.53125	(16.2s)
epoch: 96	train loss: 21852.201171875	(16.2s)
epoch: 97	train loss: 22646.681640625	(16.2s)
epoch: 98	train loss: 22561.53125	(16.2s)
epoch: 99	train loss: 22747.68359375	(16.2s)
Evaluating model on 200 episodes
0.0020025346748298034
0.012687804337474518
0.003942245384678245
0.004838680004468188
0.0009431961225345731
0.005753657431341708
0.0037402440211735666
0.0019108513370156288
0.003301266309184333
0.0040707402185944375
0.0031961660230687508
0.0018380137626081705
0.001535081973997876
0.007474978997682531
0.006383842846844345
0.013087015637817482
0.005725909606553614
0.0035104918642900884
0.0032412601867690682
0.003327822506738206
0.0036249341937946156
0.006009344418998808
0.003290457755792886
0.0029700526501983404
0.018151014281708438
0.004352453179308213
0.006965295663879563
0.0030359532102011144
0.004973714142882575
0.002443829628949364
0.00456938415300101
0.002674217258269588
0.005769988719839603
0.005476281454320997
0.004101250631113847
0.003029447980225086
0.003781932726269588
0.003678358316392405
0.005392904538894072
0.0040111474809236825
0.007103909563738853
0.005721087974961847
0.0025485465303063393
0.004804312135092914
0.003891416476108134
0.003263234432476262
0.010765690763946623
0.006388716588844545
0.005999616696499288
0.004715590825071558
0.006515899091027677
0.00892299073166214
0.003043398552108556
0.00460927611857187
0.004198349561193027
0.004781093659403268
0.006151329803590973
0.0037251815665513277
0.002930247690528631
0.004325302550569177
0.004052106669405475
0.0018605763034429401
0.0026948373997583985
0.004320538850151934
0.002359584982817372
0.0007871769485063851
0.0031408438662765548
0.005759136169217527
0.0012200272758491337
0.0027125524647999555
0.003097963798306106
0.004314842994790524
0.0023135391529649496
0.0037478331554060182
0.004209744355951746
0.003951487829908729
0.0054862440495829405
0.004057097900658846
0.004173931007971987
0.004654079811492314
0.004695930037996732
0.003218171128537506
0.004015964401332894
0.005021341401152313
0.0032249632640741765
0.004009318246971816
0.003367671265732497
0.00519913205789635
0.0009535244316793978
0.003234430798329413
0.006110145419370383
0.007617788040079176
0.0017607522750040516
0.0014389458810910583
0.006852512868742148
0.005397563159931451
0.002615083057510977
0.00536269077565521
0.0038110856936934092
0.0025414630654267967
0.010251033015083521
0.001654020685236901
0.007893575510631004
0.004808245517779142
0.005533897201530635
Solved 105/200 episodes
0.0023736117556630533
Evaluated model in 22.6 seconds
Saved model for run
e58cb3f68e74461db96fef71db8b8796 with name round-10
Round 11
Generated trajectories in 72.4 seconds
epoch: 0	train loss: 49918.82421875	(16.3s)
epoch: 1	train loss: 41774.1796875	(16.2s)
epoch: 2	train loss: 37914.67578125	(16.3s)
epoch: 3	train loss: 35299.52734375	(16.3s)
epoch: 4	train loss: 33885.859375	(16.4s)
epoch: 5	train loss: 32715.2265625	(16.4s)
epoch: 6	train loss: 31690.576171875	(16.4s)
epoch: 7	train loss: 30814.52734375	(16.4s)
epoch: 8	train loss: 30408.376953125	(16.4s)
epoch: 9	train loss: 30462.83203125	(16.4s)
epoch: 10	train loss: 29737.57421875	(16.4s)
epoch: 11	train loss: 29249.533203125	(16.4s)
epoch: 12	train loss: 28910.435546875	(16.4s)
epoch: 13	train loss: 28345.982421875	(16.4s)
epoch: 14	train loss: 27676.560546875	(16.4s)
epoch: 15	train loss: 27756.3515625	(16.4s)
epoch: 16	train loss: 28205.87890625	(16.4s)
epoch: 17	train loss: 27807.578125	(16.4s)
epoch: 18	train loss: 27452.48046875	(16.4s)
epoch: 19	train loss: 26937.671875	(16.4s)
epoch: 20	train loss: 26576.248046875	(16.4s)
epoch: 21	train loss: 26231.279296875	(16.4s)
epoch: 22	train loss: 26525.08984375	(16.4s)
epoch: 23	train loss: 26172.30859375	(16.4s)
epoch: 24	train loss: 25857.181640625	(16.4s)
epoch: 25	train loss: 25499.84375	(16.4s)
epoch: 26	train loss: 25641.70703125	(16.4s)
epoch: 27	train loss: 27173.7890625	(16.4s)
epoch: 28	train loss: 25688.85546875	(16.4s)
epoch: 29	train loss: 25847.244140625	(16.3s)
epoch: 30	train loss: 25223.61328125	(16.4s)
epoch: 31	train loss: 25424.0625	(16.4s)
epoch: 32	train loss: 25184.763671875	(16.3s)
epoch: 33	train loss: 25789.828125	(16.3s)
epoch: 34	train loss: 24890.53515625	(16.3s)
epoch: 35	train loss: 24834.03515625	(16.4s)
epoch: 36	train loss: 25224.025390625	(16.4s)
epoch: 37	train loss: 24900.134765625	(16.4s)
epoch: 38	train loss: 24504.87890625	(16.4s)
epoch: 39	train loss: 24565.095703125	(16.4s)
epoch: 40	train loss: 24263.017578125	(16.4s)
epoch: 41	train loss: 24270.431640625	(16.4s)
epoch: 42	train loss: 23536.15234375	(16.4s)
epoch: 43	train loss: 23480.82421875	(16.4s)
epoch: 44	train loss: 23466.3984375	(16.4s)
epoch: 45	train loss: 23756.966796875	(16.4s)
epoch: 46	train loss: 24209.091796875	(16.4s)
epoch: 47	train loss: 24049.556640625	(16.4s)
epoch: 48	train loss: 23788.509765625	(16.4s)
epoch: 49	train loss: 24229.353515625	(16.4s)
epoch: 50	train loss: 24257.748046875	(16.4s)
epoch: 51	train loss: 23675.478515625	(16.4s)
epoch: 52	train loss: 24332.970703125	(16.4s)
epoch: 53	train loss: 23672.462890625	(16.4s)
epoch: 54	train loss: 23430.701171875	(16.4s)
epoch: 55	train loss: 23081.84765625	(16.4s)
epoch: 56	train loss: 23205.412109375	(16.4s)
epoch: 57	train loss: 23169.791015625	(16.4s)
epoch: 58	train loss: 23117.5703125	(16.4s)
epoch: 59	train loss: 23139.611328125	(16.4s)
epoch: 60	train loss: 24106.734375	(16.4s)
epoch: 61	train loss: 23808.6640625	(16.4s)
epoch: 62	train loss: 23393.34765625	(16.4s)
epoch: 63	train loss: 23139.30859375	(16.4s)
epoch: 64	train loss: 22749.0625	(16.4s)
epoch: 65	train loss: 22498.095703125	(16.4s)
epoch: 66	train loss: 22269.4765625	(16.4s)
epoch: 67	train loss: 22698.4453125	(16.4s)
epoch: 68	train loss: 23324.1328125	(16.4s)
epoch: 69	train loss: 22847.853515625	(16.4s)
epoch: 70	train loss: 22328.79296875	(16.4s)
epoch: 71	train loss: 22727.357421875	(16.4s)
epoch: 72	train loss: 23768.68359375	(16.4s)
epoch: 73	train loss: 22468.486328125	(16.4s)
epoch: 74	train loss: 22708.455078125	(16.4s)
epoch: 75	train loss: 22463.81640625	(16.4s)
epoch: 76	train loss: 22109.91015625	(16.4s)
epoch: 77	train loss: 22118.201171875	(16.4s)
epoch: 78	train loss: 22464.41015625	(16.4s)
epoch: 79	train loss: 23330.814453125	(16.4s)
epoch: 80	train loss: 24351.400390625	(16.4s)
epoch: 81	train loss: 22524.771484375	(16.4s)
epoch: 82	train loss: 22126.59375	(16.4s)
epoch: 83	train loss: 22473.02734375	(16.4s)
epoch: 84	train loss: 22042.76171875	(16.4s)
epoch: 85	train loss: 21577.6796875	(16.4s)
epoch: 86	train loss: 21677.150390625	(16.4s)
epoch: 87	train loss: 21607.052734375	(16.4s)
epoch: 88	train loss: 21622.099609375	(16.4s)
epoch: 89	train loss: 21642.92578125	(16.4s)
epoch: 90	train loss: 22229.134765625	(16.4s)
epoch: 91	train loss: 22475.029296875	(16.4s)
epoch: 92	train loss: 21970.2734375	(16.4s)
epoch: 93	train loss: 21919.3671875	(16.4s)
epoch: 94	train loss: 21399.802734375	(16.4s)
epoch: 95	train loss: 24670.31640625	(16.4s)
epoch: 96	train loss: 22538.671875	(16.3s)
epoch: 97	train loss: 21895.279296875	(16.3s)
epoch: 98	train loss: 21457.34375	(16.3s)
epoch: 99	train loss: 21400.580078125	(16.4s)
Evaluating model on 200 episodes
0.0021960336016491055
0.0031070781406015158
0.0031967721733963117
0.0031784476013854146
0.0023383806158866114
0.0027808608914104602
0.002217228611698374
0.0033164284638284394
0.006935085169970989
0.003777631267439574
0.004654521704651415
0.0018559798772912472
0.0021821968748554355
0.0033124950423371047
0.0023052189111088714
0.00319106483948417
0.004604234045837074
0.007082602164397637
0.017508674432368327
0.003183773922501132
0.004729704174678773
0.004698901437222958
0.007645165605936199
0.005353087248901526
0.002174245339119807
0.004809706518426537
0.00265166797908023
0.006942404123644034
0.003594939078902826
0.0026214485988020897
0.003511953924316913
0.002622953150421381
0.001396709805703722
0.001966395902854856
0.08551309954297419
0.004528587847016752
0.0022504975786432624
0.002528283977881074
0.004864217131398618
0.007131492858752609
0.002268768963404
0.0034697405353654176
0.0030270724382717162
0.002787744117085822
0.006783310062019154
0.0027335950289852917
0.0030648887623101473
0.004432304859316598
0.0013908319670008495
0.009389245169586502
0.004166753846220672
0.0018927250299990799
0.003211576637113467
0.002863616209651809
0.002644310867860137
0.0032390894872757294
0.0028343236966369054
0.003066383535042405
0.0017619321394401293
0.004220560134854168
0.0031765022467880044
0.0032604485168121755
0.0044000795132888015
0.0012740596430376172
0.0024262614715553354
0.002472413242988599
0.0019507083343341947
0.002163754339562729
0.0016283731674775481
0.0021679476485587656
0.005228984417044558
0.0036689321229156726
0.004427832958754152
0.002137334377039224
0.002108904911438003
0.004553931998088956
0.007059591667105754
0.0027288022683933377
0.004322479517819981
0.003594100140617229
0.0044458761345595125
0.007927183818537742
0.0027577654109336436
0.005296544247539714
0.0036950403242371976
0.0017316107017298539
0.004211678504361771
0.0021024595480412245
0.0034478879145657024
0.003153333251248114
0.02148223340433712
0.0049347463209414855
0.0022688057797495276
0.0035522008511179592
0.003925024066120386
0.0034161480361944996
0.00195429747691378
0.062142912220830716
0.00387805889477022
0.002952305663105411
0.0019478306930977851
Solved 101/200 episodes
0.002648421647153858
Evaluated model in 21.2 seconds
Saved model for run
e58cb3f68e74461db96fef71db8b8796 with name round-11
Round 12
Generated trajectories in 73.4 seconds
epoch: 0	train loss: 48895.09765625	(16.4s)
epoch: 1	train loss: 40435.0390625	(16.3s)
epoch: 2	train loss: 37085.5234375	(16.4s)
epoch: 3	train loss: 34845.48828125	(16.3s)
epoch: 4	train loss: 33442.26171875	(16.5s)
epoch: 5	train loss: 32573.8125	(16.5s)
epoch: 6	train loss: 32628.90234375	(16.5s)
epoch: 7	train loss: 31843.94921875	(16.3s)
epoch: 8	train loss: 31372.244140625	(16.3s)
epoch: 9	train loss: 30229.953125	(16.4s)
epoch: 10	train loss: 29793.40234375	(16.5s)
epoch: 11	train loss: 30038.15234375	(16.4s)
epoch: 12	train loss: 28720.060546875	(16.4s)
epoch: 13	train loss: 29226.48828125	(16.5s)
epoch: 14	train loss: 27869.904296875	(16.5s)
epoch: 15	train loss: 27391.640625	(16.4s)
epoch: 16	train loss: 27080.921875	(16.4s)
epoch: 17	train loss: 26799.013671875	(16.4s)
epoch: 18	train loss: 26812.1796875	(16.4s)
epoch: 19	train loss: 26560.841796875	(16.5s)
epoch: 20	train loss: 26666.404296875	(16.4s)
epoch: 21	train loss: 27303.234375	(16.4s)
epoch: 22	train loss: 26777.248046875	(16.4s)
epoch: 23	train loss: 26167.072265625	(16.5s)
epoch: 24	train loss: 25862.724609375	(16.3s)
epoch: 25	train loss: 25856.384765625	(16.4s)
epoch: 26	train loss: 25684.173828125	(16.5s)
epoch: 27	train loss: 25676.8671875	(16.5s)
epoch: 28	train loss: 25881.06640625	(16.5s)
epoch: 29	train loss: 25588.728515625	(16.4s)
epoch: 30	train loss: 26742.01171875	(16.5s)
epoch: 31	train loss: 26825.763671875	(16.4s)
epoch: 32	train loss: 26145.0078125	(16.4s)
epoch: 33	train loss: 25456.71484375	(16.5s)
epoch: 34	train loss: 26252.484375	(16.3s)
epoch: 35	train loss: 25862.029296875	(16.3s)
epoch: 36	train loss: 25349.76171875	(16.5s)
epoch: 37	train loss: 24994.931640625	(16.4s)
epoch: 38	train loss: 24460.041015625	(16.4s)
epoch: 39	train loss: 24450.87890625	(16.3s)
epoch: 40	train loss: 24292.7578125	(16.4s)
epoch: 41	train loss: 23988.818359375	(16.4s)
epoch: 42	train loss: 24049.62109375	(16.5s)
epoch: 43	train loss: 23841.66796875	(16.4s)
epoch: 44	train loss: 24545.404296875	(16.4s)
epoch: 45	train loss: 24140.087890625	(16.4s)
epoch: 46	train loss: 24251.828125	(16.5s)
epoch: 47	train loss: 24243.958984375	(16.5s)
epoch: 48	train loss: 23860.01171875	(16.4s)
epoch: 49	train loss: 23727.966796875	(16.4s)
epoch: 50	train loss: 24540.75390625	(16.5s)
epoch: 51	train loss: 26572.501953125	(16.4s)
epoch: 52	train loss: 24500.1484375	(16.4s)
epoch: 53	train loss: 24272.810546875	(16.5s)
epoch: 54	train loss: 24483.28125	(16.3s)
epoch: 55	train loss: 23867.03125	(16.4s)
epoch: 56	train loss: 23574.712890625	(16.4s)
epoch: 57	train loss: 23472.767578125	(16.5s)
epoch: 58	train loss: 23148.111328125	(16.4s)
epoch: 59	train loss: 23522.6796875	(16.5s)
epoch: 60	train loss: 23132.33203125	(16.5s)
epoch: 61	train loss: 23125.51953125	(16.4s)
epoch: 62	train loss: 24065.6015625	(16.5s)
epoch: 63	train loss: 23681.587890625	(16.4s)
epoch: 64	train loss: 23059.953125	(16.5s)
epoch: 65	train loss: 23217.658203125	(16.5s)
epoch: 66	train loss: 23542.029296875	(16.4s)
epoch: 67	train loss: 23203.970703125	(16.4s)
epoch: 68	train loss: 23269.25390625	(16.4s)
epoch: 69	train loss: 23667.490234375	(16.5s)
epoch: 70	train loss: 24968.357421875	(16.3s)
epoch: 71	train loss: 23118.6328125	(16.3s)
epoch: 72	train loss: 22879.564453125	(16.4s)
epoch: 73	train loss: 22711.283203125	(16.4s)
epoch: 74	train loss: 22965.046875	(16.5s)
epoch: 75	train loss: 27246.078125	(16.3s)
epoch: 76	train loss: 24834.4453125	(16.5s)
epoch: 77	train loss: 23919.27734375	(16.4s)
epoch: 78	train loss: 23836.021484375	(16.4s)
epoch: 79	train loss: 23057.73046875	(16.4s)
epoch: 80	train loss: 22588.791015625	(16.4s)
epoch: 81	train loss: 22394.240234375	(16.4s)
epoch: 82	train loss: 22290.5078125	(16.5s)
epoch: 83	train loss: 22525.83984375	(16.5s)
epoch: 84	train loss: 22425.794921875	(16.5s)
epoch: 85	train loss: 22339.19140625	(16.4s)
epoch: 86	train loss: 22155.3828125	(16.4s)
epoch: 87	train loss: 21996.6015625	(16.4s)
epoch: 88	train loss: 21861.26953125	(16.5s)
epoch: 89	train loss: 22107.75	(16.4s)
epoch: 90	train loss: 22673.568359375	(16.5s)
epoch: 91	train loss: 23092.5390625	(16.3s)
epoch: 92	train loss: 22569.291015625	(16.3s)
epoch: 93	train loss: 22470.1171875	(16.5s)
epoch: 94	train loss: 22357.103515625	(16.5s)
epoch: 95	train loss: 22277.068359375	(16.4s)
epoch: 96	train loss: 22186.36328125	(16.3s)
epoch: 97	train loss: 22705.93359375	(16.4s)
epoch: 98	train loss: 23322.912109375	(16.4s)
epoch: 99	train loss: 23896.203125	(16.3s)
Evaluating model on 200 episodes
0.002280715765664354
0.003648651111871004
0.002293439843924716
0.0028759120614267886
0.003447107900865376
0.004245025721112532
0.002385630941716954
0.0030965595700157187
0.003670862119179219
0.002856996492482722
0.0027378599043004215
0.0030162448529154062
0.003704346891026944
0.0023673983911673227
0.0034927729284390807
0.0045833567855879664
0.0035952601581811907
0.001933339866809547
0.0019404166523599997
0.0008303163922391832
0.0017162277363240719
0.0029647756018675864
0.0021638732869178057
0.0022656098008155823
0.007323018818472822
0.0026169729535467923
0.002598621358629316
0.0021688255365006626
0.0027938708080910146
0.0015705116384197026
0.004101802478544414
0.0044315490173175934
0.00513130403123796
0.004414911090862006
0.0029112258751410993
0.0030843926360830665
0.003123841694711397
0.0040976952683801455
0.0023208577767945826
0.0032245208664486804
0.0033387078437954187
0.002324433356989175
0.003455946303438395
0.002104023762512952
0.005705300951376557
0.0015580059844069183
0.0024809298920445144
0.0072906335117295384
0.003100387053564191
0.0036840008688159287
0.00371281448751688
0.003286424500402063
0.005391521565616131
0.00544570607598871
0.002557107713073492
0.0037240634090267124
0.002869986230507493
0.0032508365577086805
0.003973608231171965
0.004707298474386334
0.0019880307372659445
0.001165685011073947
0.002651639864780009
0.002990329870954156
0.0021734650945290923
0.003974755837892492
0.0021484741009771824
0.003966023757432898
0.002247700747102499
0.002162680417920152
0.004756190837360919
0.0019183325348421931
0.0023750171822030097
0.001293479188461788
0.0033711569849401712
0.0027843469496084644
0.0014342955546453595
0.0024799592792987823
0.002542297396576032
0.0030021855054656044
0.0030443551562105617
0.0014447103603743017
0.002532683778554201
0.0011661775643005967
0.002667288645170629
0.0022873940179124475
0.004843161744065583
0.0031880696769803762
0.00356125581311062
0.0038745301426388323
0.004090904025360942
0.0056344133336097
0.0029607348842546344
Solved 93/200 episodes
0.0014535504269816946
Evaluated model in 22.8 seconds
Saved model for run
e58cb3f68e74461db96fef71db8b8796 with name round-12
Round 13
Generated trajectories in 72.5 seconds
epoch: 0	train loss: 47619.7421875	(16.3s)
epoch: 1	train loss: 40008.74609375	(16.3s)
epoch: 2	train loss: 36346.171875	(16.3s)
epoch: 3	train loss: 34178.55859375	(16.4s)
epoch: 4	train loss: 33011.58984375	(16.4s)
epoch: 5	train loss: 32036.767578125	(16.4s)
epoch: 6	train loss: 31114.419921875	(16.4s)
epoch: 7	train loss: 30244.28125	(16.4s)
epoch: 8	train loss: 29534.888671875	(16.4s)
epoch: 9	train loss: 29052.19921875	(16.4s)
epoch: 10	train loss: 28626.3828125	(16.4s)
epoch: 11	train loss: 28412.302734375	(16.4s)
epoch: 12	train loss: 28132.48046875	(16.4s)
epoch: 13	train loss: 27641.90234375	(16.4s)
epoch: 14	train loss: 28461.517578125	(16.4s)
epoch: 15	train loss: 27636.998046875	(16.4s)
epoch: 16	train loss: 27139.263671875	(16.4s)
epoch: 17	train loss: 28414.58984375	(16.4s)
epoch: 18	train loss: 27298.560546875	(16.4s)
epoch: 19	train loss: 26690.45703125	(16.4s)
epoch: 20	train loss: 26384.416015625	(16.4s)
epoch: 21	train loss: 25952.86328125	(16.5s)
epoch: 22	train loss: 25619.388671875	(16.5s)
epoch: 23	train loss: 26092.9140625	(16.4s)
epoch: 24	train loss: 25719.7578125	(16.4s)
epoch: 25	train loss: 25262.755859375	(16.5s)
epoch: 26	train loss: 25144.73828125	(16.5s)
epoch: 27	train loss: 25084.54296875	(16.5s)
epoch: 28	train loss: 25439.48046875	(16.4s)
epoch: 29	train loss: 25189.98828125	(16.4s)
epoch: 30	train loss: 24855.4296875	(16.5s)
epoch: 31	train loss: 25271.20703125	(16.5s)
epoch: 32	train loss: 28053.533203125	(16.4s)
epoch: 33	train loss: 25951.880859375	(16.5s)
epoch: 34	train loss: 25146.427734375	(16.4s)
epoch: 35	train loss: 25333.185546875	(16.4s)
epoch: 36	train loss: 24543.015625	(16.4s)
epoch: 37	train loss: 24644.845703125	(16.4s)
epoch: 38	train loss: 24142.466796875	(16.5s)
epoch: 39	train loss: 23932.865234375	(16.5s)
epoch: 40	train loss: 24018.845703125	(16.5s)
epoch: 41	train loss: 24156.796875	(16.5s)
epoch: 42	train loss: 24074.5546875	(16.5s)
epoch: 43	train loss: 23523.142578125	(16.5s)
epoch: 44	train loss: 23320.798828125	(16.5s)
epoch: 45	train loss: 23970.109375	(16.5s)
epoch: 46	train loss: 23589.28125	(16.5s)
epoch: 47	train loss: 24928.578125	(16.5s)
epoch: 48	train loss: 23908.2421875	(16.6s)
epoch: 49	train loss: 23873.693359375	(16.5s)
epoch: 50	train loss: 23746.765625	(16.4s)
epoch: 51	train loss: 25120.14453125	(16.5s)
epoch: 52	train loss: 23989.603515625	(16.5s)
epoch: 53	train loss: 23885.076171875	(16.5s)
epoch: 54	train loss: 23591.650390625	(16.5s)
epoch: 55	train loss: 22873.091796875	(16.4s)
epoch: 56	train loss: 22991.435546875	(16.5s)
epoch: 57	train loss: 22833.97265625	(16.5s)
epoch: 58	train loss: 22771.712890625	(16.5s)
epoch: 59	train loss: 22568.16015625	(16.5s)
epoch: 60	train loss: 22494.197265625	(16.4s)
epoch: 61	train loss: 24022.908203125	(16.5s)
epoch: 62	train loss: 23920.7265625	(16.5s)
epoch: 63	train loss: 23697.07421875	(16.5s)
epoch: 64	train loss: 24591.896484375	(16.5s)
epoch: 65	train loss: 24255.232421875	(16.4s)
epoch: 66	train loss: 23780.99609375	(16.4s)
epoch: 67	train loss: 23662.65625	(16.5s)
epoch: 68	train loss: 23348.529296875	(16.5s)
epoch: 69	train loss: 22716.09375	(16.5s)
epoch: 70	train loss: 22213.974609375	(16.5s)
epoch: 71	train loss: 22197.11328125	(16.5s)
epoch: 72	train loss: 22111.30078125	(16.5s)
epoch: 73	train loss: 22298.044921875	(16.5s)
epoch: 74	train loss: 21993.55078125	(16.5s)
epoch: 75	train loss: 22381.205078125	(16.5s)
epoch: 76	train loss: 23103.23046875	(16.5s)
epoch: 77	train loss: 22705.84765625	(16.5s)
epoch: 78	train loss: 22954.8046875	(16.6s)
epoch: 79	train loss: 22331.095703125	(16.5s)
epoch: 80	train loss: 22502.509765625	(16.5s)
epoch: 81	train loss: 22641.19140625	(16.5s)
epoch: 82	train loss: 22581.017578125	(16.5s)
epoch: 83	train loss: 22271.0859375	(16.5s)
epoch: 84	train loss: 21879.05859375	(16.5s)
epoch: 85	train loss: 21757.65625	(16.5s)
epoch: 86	train loss: 21466.416015625	(16.5s)
epoch: 87	train loss: 22122.439453125	(16.5s)
epoch: 88	train loss: 22066.953125	(16.5s)
epoch: 89	train loss: 22042.4375	(16.5s)
epoch: 90	train loss: 21658.970703125	(16.5s)
epoch: 91	train loss: 21580.24609375	(16.5s)
epoch: 92	train loss: 21455.244140625	(16.5s)
epoch: 93	train loss: 22098.787109375	(16.5s)
epoch: 94	train loss: 21822.333984375	(16.5s)
epoch: 95	train loss: 22294.55859375	(16.5s)
epoch: 96	train loss: 22649.626953125	(16.5s)
epoch: 97	train loss: 22760.888671875	(16.5s)
epoch: 98	train loss: 22330.69921875	(16.5s)
epoch: 99	train loss: 21663.2734375	(16.5s)
Evaluating model on 200 episodes
0.00512271307525225
0.003600016760174185
0.004711739020422101
0.0043048828665632755
0.008124591192297106
0.002809238460031338
0.0029260748997330666
0.004091640643309802
0.0018119445303454995
0.003806192835327238
0.003685444695292972
0.0019733114750124514
0.002594153474395474
0.00203632382908836
0.005459003751942267
0.0024400484981015325
0.0025799137220019475
0.0018871230228493612
0.003104233726238211
0.00426802271977067
0.0028569524292834103
0.006633666926063597
0.0030975609697634354
0.005622903234325349
0.002970075664052274
0.0050514114773250185
0.0005186637863516808
0.0018507869002254058
0.0035132447170326485
0.0021977800449045994
0.00601985226967372
0.004267133575922344
0.0036738793132826686
0.0030706145626027137
0.006331619253614917
0.0028393587175135813
0.004947337176417932
0.0018293126486241817
0.003838156163692474
0.004873119595382984
0.005327697246684693
0.00362456506700255
0.0016669560864102095
0.0031053832062752917
0.0027612404664978385
0.0026657529233489186
0.004108008019102272
0.0036952795926481485
0.005576729029417038
0.0024291560985147953
0.002228398807346821
0.009219027900447449
0.0021483415233281753
0.002196199377067387
0.003842088335659355
0.0035478498903103173
0.011666018392133992
0.004373557865619659
0.0053568805354492115
0.0053709498994673295
0.001161922118626535
0.0031161281100745932
0.002129890606738627
0.00342115928651765
0.0028902446647407487
0.0014842204982414842
0.0024253204464912415
0.0031016564074282846
0.004555145758786239
0.001169659117294941
0.003483462263830006
0.005744316993514076
0.004374154377728701
0.0019691320339916274
0.004048781582241645
0.003522607483319007
0.004342250729678199
0.0016874471621122211
0.0028418838961182962
0.002447362174279988
0.00439946223438407
0.0050969605217687786
0.004471460677450523
0.0019088247863692231
0.0023972932249307632
0.005948559691508611
0.007483200402930379
0.003123335503914859
0.0021514048567041755
0.003595454579529663
0.0008618016145192087
0.004524372115459603
0.0024971443344838917
0.0030197946956225983
0.00483526547322981
0.0030474720988422632
0.0035836240470719836
0.0011888629087479785
0.002378367236815393
0.020320108439773322
0.14064738463493995
0.0023928698792587966
0.00461932704395925
0.004319340000317122
0.003080838449022849
0.0035616427165223287
0.005114519619382918
0.007093353793607093
0.003197476345424851
0.002828795581687397
0.0019044764436936628
0.00574261379855064
0.005587020982056856
0.004361592931672931
0.009155742343864404
0.003937911620596424
0.004446442340849899
0.001126007700804621
0.004437668404231469
0.002410344692179933
Solved 120/200 episodes
0.00299482503682685
Evaluated model in 22.5 seconds
Saved model for run
e58cb3f68e74461db96fef71db8b8796 with name round-13
Round 14
Generated trajectories in 73.9 seconds
epoch: 0	train loss: 45696.29296875	(16.5s)
epoch: 1	train loss: 38150.3359375	(16.4s)
epoch: 2	train loss: 34892.38671875	(16.4s)
epoch: 3	train loss: 32936.578125	(16.4s)
epoch: 4	train loss: 31424.125	(16.5s)
epoch: 5	train loss: 30482.12109375	(16.5s)
epoch: 6	train loss: 29822.193359375	(16.4s)
epoch: 7	train loss: 29599.16796875	(16.4s)
epoch: 8	train loss: 29077.681640625	(16.4s)
epoch: 9	train loss: 28738.271484375	(16.4s)
epoch: 10	train loss: 28607.619140625	(16.5s)
epoch: 11	train loss: 28179.236328125	(16.4s)
epoch: 12	train loss: 28168.576171875	(16.4s)
epoch: 13	train loss: 27277.7421875	(16.4s)
epoch: 14	train loss: 27826.09375	(16.4s)
epoch: 15	train loss: 27771.78515625	(16.4s)
epoch: 16	train loss: 26974.1015625	(16.4s)
epoch: 17	train loss: 26350.177734375	(16.4s)
epoch: 18	train loss: 26021.171875	(16.4s)
epoch: 19	train loss: 25856.724609375	(16.4s)
epoch: 20	train loss: 26067.033203125	(16.4s)
epoch: 21	train loss: 25460.671875	(16.4s)
epoch: 22	train loss: 25248.36328125	(16.4s)
epoch: 23	train loss: 25138.4296875	(16.4s)
epoch: 24	train loss: 24854.611328125	(16.4s)
epoch: 25	train loss: 24895.443359375	(16.4s)
epoch: 26	train loss: 27857.138671875	(16.4s)
epoch: 27	train loss: 26876.5078125	(16.4s)
epoch: 28	train loss: 25843.8046875	(16.4s)
epoch: 29	train loss: 25204.5	(16.4s)
epoch: 30	train loss: 24790.599609375	(16.4s)
epoch: 31	train loss: 25336.6171875	(16.4s)
epoch: 32	train loss: 25422.96875	(16.4s)
epoch: 33	train loss: 24953.36328125	(16.4s)
epoch: 34	train loss: 24670.953125	(16.3s)
epoch: 35	train loss: 24372.31640625	(16.4s)
epoch: 36	train loss: 24045.978515625	(16.5s)
epoch: 37	train loss: 23664.0390625	(16.4s)
epoch: 38	train loss: 23544.71484375	(16.5s)
epoch: 39	train loss: 23574.10546875	(16.4s)
epoch: 40	train loss: 23333.1640625	(16.5s)
epoch: 41	train loss: 23379.046875	(16.5s)
epoch: 42	train loss: 23811.060546875	(16.5s)
epoch: 43	train loss: 23793.0703125	(16.5s)
epoch: 44	train loss: 23622.10546875	(16.4s)
epoch: 45	train loss: 24766.44140625	(16.4s)
epoch: 46	train loss: 26340.009765625	(16.5s)
epoch: 47	train loss: 25062.919921875	(16.5s)
epoch: 48	train loss: 25450.921875	(16.5s)
epoch: 49	train loss: 24318.345703125	(16.5s)
epoch: 50	train loss: 23639.673828125	(16.5s)
epoch: 51	train loss: 23550.482421875	(16.5s)
epoch: 52	train loss: 23845.103515625	(16.5s)
epoch: 53	train loss: 24053.22265625	(16.5s)
epoch: 54	train loss: 23509.4921875	(16.5s)
epoch: 55	train loss: 23255.404296875	(16.4s)
epoch: 56	train loss: 22937.966796875	(16.5s)
epoch: 57	train loss: 23374.513671875	(16.5s)
epoch: 58	train loss: 23872.33984375	(16.5s)
epoch: 59	train loss: 23180.53515625	(16.4s)
epoch: 60	train loss: 24050.337890625	(16.5s)
epoch: 61	train loss: 23135.53515625	(16.5s)
epoch: 62	train loss: 22723.396484375	(16.5s)
epoch: 63	train loss: 23444.25390625	(16.5s)
epoch: 64	train loss: 22892.765625	(16.5s)
epoch: 65	train loss: 22562.390625	(16.4s)
epoch: 66	train loss: 22940.08203125	(16.5s)
epoch: 67	train loss: 22455.517578125	(16.5s)
epoch: 68	train loss: 22155.369140625	(16.5s)
epoch: 69	train loss: 22161.4921875	(16.4s)
epoch: 70	train loss: 23533.98828125	(16.4s)
epoch: 71	train loss: 22507.177734375	(16.5s)
epoch: 72	train loss: 23586.298828125	(16.5s)
epoch: 73	train loss: 24121.876953125	(16.5s)
epoch: 74	train loss: 23262.125	(16.4s)
epoch: 75	train loss: 22620.177734375	(16.4s)
epoch: 76	train loss: 22659.796875	(16.5s)
epoch: 77	train loss: 22696.26171875	(16.5s)
epoch: 78	train loss: 22394.349609375	(16.5s)
epoch: 79	train loss: 22375.013671875	(16.5s)
epoch: 80	train loss: 24601.748046875	(16.4s)
epoch: 81	train loss: 22729.787109375	(16.5s)
epoch: 82	train loss: 23470.27734375	(16.5s)
epoch: 83	train loss: 23082.83203125	(16.5s)
epoch: 84	train loss: 21927.783203125	(16.5s)
epoch: 85	train loss: 21702.154296875	(16.4s)
epoch: 86	train loss: 21521.72265625	(16.4s)
epoch: 87	train loss: 21930.48828125	(16.4s)
epoch: 88	train loss: 22315.3984375	(16.4s)
epoch: 89	train loss: 22831.236328125	(16.5s)
epoch: 90	train loss: 22197.435546875	(16.4s)
epoch: 91	train loss: 22642.609375	(16.4s)
epoch: 92	train loss: 23831.19140625	(16.4s)
epoch: 93	train loss: 24422.39453125	(16.5s)
epoch: 94	train loss: 22770.515625	(16.4s)
epoch: 95	train loss: 22142.3515625	(16.4s)
epoch: 96	train loss: 22032.107421875	(16.4s)
epoch: 97	train loss: 21600.53125	(16.4s)
epoch: 98	train loss: 21299.705078125	(16.4s)
epoch: 99	train loss: 21229.615234375	(16.4s)
Evaluating model on 200 episodes
0.005159785522014967
0.003460749324100713
0.0025337981060147285
0.0031325135496445
0.004859228196437471
0.00632893321744632
0.003917788999387994
0.0020882023964077234
0.004610984072011585
0.002568380926580479
0.004137504147365689
0.006557290704222396
0.002246660369564779
0.002563695452408865
0.0034730154244850078
0.0034500704787205905
0.0018452350438262026
0.006257155298953876
0.0024573878617957234
0.0035990126780234277
0.0028638763003982605
0.0030398273083847016
0.00506961764767766
0.003053178923437372
0.001819904486183077
0.003764255455462262
0.004029009161361803
0.003921427443856373
0.002383939310675487
0.0029985579196363686
0.011868515118424381
0.0042817252106033266
0.002642938052304089
0.0026751269663994512
0.002794782561250031
0.00417105639159369
0.0031326273650241396
0.013254013999054829
0.0012038657150696963
0.004080592072568834
0.003972176171373576
0.0006721786048728973
0.009548258851282299
0.009852863110912343
0.005079263064544648
0.0026556778078277907
0.0022126807773020117
0.004330163181293756
0.0026186769052098193
0.0048191475798375905
0.006291117914952338
0.0038180219125933945
0.0022985585266724227
0.001996287959627807
0.003003583289682865
0.003677193133626133
0.011004911444615573
0.002112771493557375
0.0016334848284410934
0.006900456178383055
0.001440455496776849
0.0008391344599658623
0.0018511040446658928
0.0035312990366946906
0.0036342544481158257
0.001714841346256435
0.00440641597378999
0.008300156914629042
0.0018135090649593621
0.0026156121554474034
0.003487017660518177
0.002652754308655858
0.005354575424765547
0.00303738284856081
0.00451745669124648
0.005246342334430665
0.0035895391600206496
0.00433917068100224
0.005362168187275529
0.005633386899717152
0.003525225922930986
0.005931532136552657
0.002187109629934033
0.0022211913019418716
0.003224844142096117
0.003790048969676718
0.003661115071736276
0.0023447858402505517
0.006739032396581024
0.0030660176707897335
0.0030770871526328847
0.004587500588968396
0.003603421710431576
0.00670774350874126
0.004428513842867687
0.003242209873860702
0.002214200678281486
0.002967709006043151
0.005241087405011058
0.006604611786315218
0.006840164118329994
0.003149845916777849
0.004161676770308986
0.0028308428823947906
0.002064156549749896
0.0033890746611480913
0.0036747904086951166
0.0026030702283605933
0.00323428320310389
0.006678236153675243
0.002599142855615355
0.0017426058378381033
0.004094059360795654
0.0030487398616969585
0.0025257665183744393
0.0031191499438136816
0.0045335786999203265
0.0023852565209381282
0.0031601823090265193
0.004462895100004971
0.00212140244548209
0.0012874312451458536
Solved 122/200 episodes
0.00236615809639861
Evaluated model in 24.4 seconds
Saved model for run
e58cb3f68e74461db96fef71db8b8796 with name round-14
Round 15
Generated trajectories in 72.3 seconds
epoch: 0	train loss: 43796.765625	(16.3s)
epoch: 1	train loss: 36766.95703125	(16.2s)
epoch: 2	train loss: 33656.37890625	(16.3s)
epoch: 3	train loss: 31890.076171875	(16.4s)
epoch: 4	train loss: 31230.162109375	(16.4s)
epoch: 5	train loss: 30119.048828125	(16.4s)
epoch: 6	train loss: 29404.78515625	(16.4s)
epoch: 7	train loss: 28774.87890625	(16.4s)
epoch: 8	train loss: 28058.095703125	(16.4s)
epoch: 9	train loss: 27447.5234375	(16.4s)
epoch: 10	train loss: 27145.9375	(16.4s)
epoch: 11	train loss: 27990.26171875	(16.4s)
epoch: 12	train loss: 27948.8046875	(16.4s)
epoch: 13	train loss: 27380.884765625	(16.4s)
epoch: 14	train loss: 26607.802734375	(16.4s)
epoch: 15	train loss: 25985.716796875	(16.4s)
epoch: 16	train loss: 25856.3046875	(16.4s)
epoch: 17	train loss: 25575.60546875	(16.4s)
epoch: 18	train loss: 25352.3984375	(16.4s)
epoch: 19	train loss: 25327.005859375	(16.4s)
epoch: 20	train loss: 24921.998046875	(16.4s)
epoch: 21	train loss: 25073.0625	(16.4s)
epoch: 22	train loss: 25062.982421875	(16.4s)
epoch: 23	train loss: 24728.19140625	(16.4s)
epoch: 24	train loss: 24930.537109375	(16.4s)
epoch: 25	train loss: 24508.568359375	(16.4s)
epoch: 26	train loss: 24970.099609375	(16.4s)
epoch: 27	train loss: 27705.595703125	(16.4s)
epoch: 28	train loss: 25634.482421875	(16.2s)
epoch: 29	train loss: 24876.80078125	(16.2s)
epoch: 30	train loss: 24421.611328125	(16.2s)
epoch: 31	train loss: 24335.765625	(16.2s)
epoch: 32	train loss: 23949.60546875	(16.2s)
epoch: 33	train loss: 23928.4921875	(16.1s)
epoch: 34	train loss: 24314.568359375	(16.1s)
epoch: 35	train loss: 24219.283203125	(16.1s)
epoch: 36	train loss: 23796.806640625	(16.2s)
epoch: 37	train loss: 23531.07421875	(16.2s)
epoch: 38	train loss: 23497.314453125	(16.2s)
epoch: 39	train loss: 23277.591796875	(16.2s)
epoch: 40	train loss: 23279.22265625	(16.2s)
epoch: 41	train loss: 23549.298828125	(16.3s)
epoch: 42	train loss: 23626.9375	(16.2s)
epoch: 43	train loss: 23459.265625	(16.2s)
epoch: 44	train loss: 23526.654296875	(16.2s)
epoch: 45	train loss: 22978.46484375	(16.2s)
epoch: 46	train loss: 23126.810546875	(16.2s)
epoch: 47	train loss: 22886.6796875	(16.3s)
epoch: 48	train loss: 23181.087890625	(16.4s)
epoch: 49	train loss: 23100.6796875	(16.3s)
epoch: 50	train loss: 23295.12890625	(16.3s)
epoch: 51	train loss: 23224.298828125	(16.3s)
epoch: 52	train loss: 23325.0625	(16.3s)
epoch: 53	train loss: 24443.880859375	(16.3s)
epoch: 54	train loss: 23332.15625	(16.4s)
epoch: 55	train loss: 23700.3125	(16.3s)
epoch: 56	train loss: 23763.375	(16.3s)
epoch: 57	train loss: 23293.083984375	(16.3s)
epoch: 58	train loss: 22397.796875	(16.3s)
epoch: 59	train loss: 22168.15234375	(16.3s)
epoch: 60	train loss: 22042.486328125	(16.3s)
epoch: 61	train loss: 21839.65625	(16.3s)
epoch: 62	train loss: 22034.30078125	(16.3s)
epoch: 63	train loss: 22112.12890625	(16.3s)
epoch: 64	train loss: 22059.7109375	(16.3s)
epoch: 65	train loss: 22179.974609375	(16.3s)
epoch: 66	train loss: 21693.505859375	(16.3s)
epoch: 67	train loss: 22497.404296875	(16.3s)
epoch: 68	train loss: 22943.748046875	(16.4s)
epoch: 69	train loss: 24666.779296875	(16.4s)
epoch: 70	train loss: 28838.7578125	(16.3s)
epoch: 71	train loss: 24504.9921875	(16.3s)
epoch: 72	train loss: 23028.013671875	(16.3s)
epoch: 73	train loss: 22450.068359375	(16.3s)
epoch: 74	train loss: 22312.91015625	(16.3s)
epoch: 75	train loss: 21682.298828125	(16.3s)
epoch: 76	train loss: 21649.587890625	(16.3s)
epoch: 77	train loss: 21891.07421875	(16.3s)
epoch: 78	train loss: 21677.880859375	(16.3s)
epoch: 79	train loss: 21605.0390625	(16.3s)
epoch: 80	train loss: 22672.6640625	(16.3s)
epoch: 81	train loss: 23787.3984375	(16.2s)
epoch: 82	train loss: 22601.876953125	(16.3s)
epoch: 83	train loss: 21876.375	(16.3s)
epoch: 84	train loss: 21588.017578125	(16.3s)
epoch: 85	train loss: 21810.546875	(16.3s)
epoch: 86	train loss: 21726.76953125	(16.3s)
epoch: 87	train loss: 21546.791015625	(16.3s)
epoch: 88	train loss: 22623.638671875	(16.4s)
epoch: 89	train loss: 21950.63671875	(16.5s)
epoch: 90	train loss: 21470.96875	(16.3s)
epoch: 91	train loss: 21025.03125	(16.3s)
epoch: 92	train loss: 21216.240234375	(16.3s)
epoch: 93	train loss: 21385.978515625	(16.3s)
epoch: 94	train loss: 21281.142578125	(16.4s)
epoch: 95	train loss: 21281.31640625	(16.3s)
epoch: 96	train loss: 21472.505859375	(16.1s)
epoch: 97	train loss: 21955.279296875	(16.1s)
epoch: 98	train loss: 21586.234375	(16.3s)
epoch: 99	train loss: 21189.123046875	(16.3s)
Evaluating model on 200 episodes
0.0014436213677981868
0.004638575599528849
0.004726524697616696
0.0015487855416722596
0.002556228505757948
0.003243830578867346
0.0022218246400977173
0.004278962418902665
0.002861301569888989
0.0028743997681885958
0.0013428325376783807
0.0031414627097547053
0.006375886907335371
0.0031407841306645423
0.0009965183562599123
0.0025399804580956697
0.002396200696239248
0.0021493774256668985
0.001862383185653016
0.005402944050729275
0.0018911134102381766
0.0025260132388211787
0.0025707425171276554
0.0056995549239218235
0.00351934767968487
0.0016218818200286478
0.0026701888418756425
0.0026824026717804372
0.001704043592326343
0.004979773960076273
0.005063340213382617
0.004648391259252094
0.0031889497040538117
0.004169578038272448
0.0027263667434453964
0.0036316487938165666
0.0012069288059137762
0.0031784541982536516
0.0012924793409183621
0.002681018908333499
0.0031954979058355093
0.0038542021065950394
0.0032992309667558097
0.0012131488183513284
0.003456568983286464
0.005710527650080621
0.001780714956112206
0.00602812971919775
0.0034548533731140196
0.001276592670668227
0.0015822951099835336
0.003976251231506467
0.0039008109451970086
0.0025324812158942223
0.0034899550955742598
0.002716615446843207
0.004291284887585789
0.0016581466770730913
0.006933275377377868
0.005324727215338498
0.0017708357966815431
0.0020581528078764677
0.002754682170537611
0.004405119968578219
0.0051568285395790425
0.0035102133406326175
0.0028394848050083965
0.0025234149798052385
0.004717096744570881
0.003194939927197993
0.0020244877377990633
0.004435233461360137
0.0015607985478709452
0.07166414374175172
0.002432184584904462
0.004202270996756852
0.00308337927951167
0.003428762254770845
0.004187180238659494
0.002323932247236371
0.0008861510432325304
0.0060067614540457726
0.0037316131638363004
0.0021976582356728613
0.003193504293449223
0.0011623023892752826
0.0034067312565942607
0.0024742639652686194
0.0016601329916738905
0.002224312241499623
0.005543168284930289
0.0020076823226797083
0.004437095660250634
0.002488824259489775
0.0023048486982588656
0.0034892704570665956
0.0068502400536090136
0.007964519516099245
0.0010345772898290306
0.005576536835481723
0.004524396266788244
0.0029500086093321443
0.004910497460514307
0.005889525074356546
0.002216416352894157
0.005827794666402042
0.003924417387073238
0.0047094202163862064
0.007621014801164468
0.003956651885528117
0.0017073957133106887
0.002258775639347732
0.006098194358249505
0.0026277113938704133
0.0029373539437074214
0.003716563992202282
0.004685776911043961
0.0019043107240577228
0.0029186722822487354
0.0025459058699198065
0.0025960343627957627
0.001873077533673495
0.003575070819351822
0.004712029290385544
0.004607866663718596
0.0011045583669329062
Solved 126/200 episodes
0.002441913656644395
Evaluated model in 23.6 seconds
Saved model for run
e58cb3f68e74461db96fef71db8b8796 with name round-15
Round 16
Generated trajectories in 72.6 seconds
epoch: 0	train loss: 44545.73828125	(16.3s)
epoch: 1	train loss: 36977.34765625	(16.2s)
epoch: 2	train loss: 33800.77734375	(16.2s)
epoch: 3	train loss: 31896.69140625	(16.2s)
epoch: 4	train loss: 30591.544921875	(16.2s)
epoch: 5	train loss: 29655.423828125	(16.3s)
epoch: 6	train loss: 29245.92578125	(16.3s)
epoch: 7	train loss: 28590.234375	(16.2s)
epoch: 8	train loss: 28436.8671875	(16.2s)
epoch: 9	train loss: 28776.76953125	(16.2s)
epoch: 10	train loss: 27857.197265625	(16.3s)
epoch: 11	train loss: 27128.951171875	(16.3s)
epoch: 12	train loss: 26831.3203125	(16.3s)
epoch: 13	train loss: 26649.275390625	(16.2s)
epoch: 14	train loss: 26263.88671875	(16.2s)
epoch: 15	train loss: 26307.818359375	(16.3s)
epoch: 16	train loss: 26112.322265625	(16.3s)
epoch: 17	train loss: 25720.40625	(16.3s)
epoch: 18	train loss: 25746.091796875	(16.2s)
epoch: 19	train loss: 25776.013671875	(16.2s)
epoch: 20	train loss: 26101.650390625	(16.3s)
epoch: 21	train loss: 25985.322265625	(16.3s)
epoch: 22	train loss: 25737.7578125	(16.3s)
epoch: 23	train loss: 26137.095703125	(16.2s)
epoch: 24	train loss: 26016.837890625	(16.2s)
epoch: 25	train loss: 25309.875	(16.2s)
epoch: 26	train loss: 25033.490234375	(16.3s)
epoch: 27	train loss: 25429.296875	(16.3s)
epoch: 28	train loss: 24977.1875	(16.2s)
epoch: 29	train loss: 26565.076171875	(16.2s)
epoch: 30	train loss: 25734.306640625	(16.3s)
epoch: 31	train loss: 24603.115234375	(16.3s)
epoch: 32	train loss: 24339.87109375	(16.3s)
epoch: 33	train loss: 24473.9296875	(16.2s)
epoch: 34	train loss: 24371.693359375	(16.2s)
epoch: 35	train loss: 24168.1328125	(16.2s)
epoch: 36	train loss: 23960.46875	(16.2s)
epoch: 37	train loss: 23751.611328125	(16.2s)
epoch: 38	train loss: 23998.392578125	(16.2s)
epoch: 39	train loss: 23743.826171875	(16.2s)
epoch: 40	train loss: 23611.94921875	(16.3s)
epoch: 41	train loss: 23675.791015625	(16.3s)
epoch: 42	train loss: 23328.560546875	(16.3s)
epoch: 43	train loss: 23737.23046875	(16.3s)
epoch: 44	train loss: 23662.1328125	(16.2s)
epoch: 45	train loss: 23731.400390625	(16.2s)
epoch: 46	train loss: 23089.1796875	(16.3s)
epoch: 47	train loss: 24912.693359375	(16.3s)
epoch: 48	train loss: 24366.919921875	(16.3s)
epoch: 49	train loss: 23971.056640625	(16.2s)
epoch: 50	train loss: 23317.259765625	(16.2s)
epoch: 51	train loss: 23208.7578125	(16.3s)
epoch: 52	train loss: 23177.103515625	(16.3s)
epoch: 53	train loss: 22748.119140625	(16.3s)
epoch: 54	train loss: 23002.6875	(16.2s)
epoch: 55	train loss: 22450.970703125	(16.3s)
epoch: 56	train loss: 22904.962890625	(16.3s)
epoch: 57	train loss: 22791.38671875	(16.3s)
epoch: 58	train loss: 24272.75390625	(16.3s)
epoch: 59	train loss: 23171.119140625	(16.3s)
epoch: 60	train loss: 22799.263671875	(16.3s)
epoch: 61	train loss: 22676.697265625	(16.2s)
epoch: 62	train loss: 22726.384765625	(16.3s)
epoch: 63	train loss: 22934.3359375	(16.3s)
epoch: 64	train loss: 23360.265625	(16.3s)
epoch: 65	train loss: 22807.099609375	(16.2s)
epoch: 66	train loss: 22422.849609375	(16.2s)
epoch: 67	train loss: 22339.51953125	(16.3s)
epoch: 68	train loss: 22258.3671875	(16.3s)
epoch: 69	train loss: 22117.74609375	(16.3s)
epoch: 70	train loss: 22132.6015625	(16.2s)
epoch: 71	train loss: 22994.23046875	(16.2s)
epoch: 72	train loss: 24862.712890625	(16.3s)
epoch: 73	train loss: 23780.29296875	(16.3s)
epoch: 74	train loss: 22494.7265625	(16.3s)
epoch: 75	train loss: 22175.490234375	(16.2s)
epoch: 76	train loss: 22121.4609375	(16.2s)
epoch: 77	train loss: 21835.5	(16.3s)
epoch: 78	train loss: 21722.677734375	(16.3s)
epoch: 79	train loss: 22257.38671875	(16.3s)
epoch: 80	train loss: 22073.146484375	(16.2s)
epoch: 81	train loss: 22078.912109375	(16.2s)
epoch: 82	train loss: 21982.19921875	(16.3s)
epoch: 83	train loss: 23208.787109375	(16.3s)
epoch: 84	train loss: 22168.5390625	(16.3s)
epoch: 85	train loss: 21652.43359375	(16.3s)
epoch: 86	train loss: 21883.49609375	(16.2s)
epoch: 87	train loss: 22172.671875	(16.2s)
epoch: 88	train loss: 22672.8203125	(16.3s)
epoch: 89	train loss: 22622.83984375	(16.3s)
epoch: 90	train loss: 23733.60546875	(16.3s)
epoch: 91	train loss: 22655.861328125	(16.2s)
epoch: 92	train loss: 22297.548828125	(16.2s)
epoch: 93	train loss: 22683.474609375	(16.3s)
epoch: 94	train loss: 21988.173828125	(16.3s)
epoch: 95	train loss: 21489.09765625	(16.3s)
epoch: 96	train loss: 21112.12109375	(16.2s)
epoch: 97	train loss: 20960.8046875	(16.2s)
epoch: 98	train loss: 21588.59375	(16.2s)
epoch: 99	train loss: 21578.9921875	(16.2s)
Evaluating model on 200 episodes
0.004618576160282828
0.002361944178119302
0.0022653438112077615
0.0020811352296732366
0.003447166527621448
0.008477573283016682
0.0020460944700365267
0.002661012054886669
0.001605783763807267
0.00337813887745142
0.00392761651892215
0.0020042949763592333
0.005735215381719172
0.0012292646861169487
0.006396927376044914
0.0034535787805604437
0.0025942319334717467
0.0031583054612080255
0.007831813971279189
0.0038438313407823444
0.0067140799947083
0.010172808930898706
0.0022554692307797572
0.0022015850602959595
0.003280515879547844
0.0034552125725895166
0.007056598618094411
0.004419530897090833
0.005486668378580362
0.007680748589336872
0.005669528909493238
0.009154451234887043
0.003824387793429196
0.005479902345021921
0.007306806122263272
0.0050042992806993425
0.0051497797830961645
0.005633828074981769
0.0038415128365159035
0.002841407316736877
0.0037602197844535112
0.007321864133700728
0.006036688876338303
0.0034475144542132816
0.0017779584741219878
0.0029522081604227424
0.002615464327391237
0.0038077819044701755
0.00661356549244374
0.0015007631736807525
0.0056308099592570215
0.0032548854360356927
0.0030261451611295342
0.007911220949608833
0.002577423583716154
0.0029950181487947702
0.0035739399172598496
0.0017797519103623927
0.0022085276432335377
0.0022684730356559157
0.002678598422789946
0.0026256273267790675
0.004317926281752686
0.004211720321715499
0.004269443976227194
0.002280530442173282
0.003323206095956266
0.007551453250925988
0.002814074163325131
0.0047786567665752955
0.004145204011971752
0.005420777015388012
0.003139116413270434
0.0023519979367847554
0.0017452110187150538
0.0018041591974906623
0.00532792757730931
0.0031095393060240895
0.0022738545667380095
0.0036177446600049734
0.0043124094605445865
0.003933216503355652
0.008010911382734775
0.0031004416523501277
0.0031400149455294013
0.00167793578778704
0.0032964549027383327
0.004625449189916253
0.0034857045247917995
0.0035384189492712417
0.005810667295008898
0.0066789682023227215
0.00346324872225523
0.0033219894976355135
0.00289457623148337
0.004121774225495756
0.00334494118578732
0.0032980480464175344
0.00522748214037468
0.00727818813174963
0.007344297210996349
0.005022081534843892
0.003967805540014524
0.00516617998558407
0.0015869785565882921
0.005720018246211112
0.0027724307340880236
0.003482983670740699
0.005838143371511251
0.0047289074398577215
0.0021666010143235326
0.006144611514173448
0.0029150492143041142
0.003734505851753056
0.005050761174061336
0.00413677734710897
0.004097835684660822
0.0036319008067948744
0.011605360452085734
0.004027844755910337
0.002791354044650992
0.0020014806650578976
Solved 122/200 episodes
0.002545443568513465
Evaluated model in 25.4 seconds
Saved model for run
e58cb3f68e74461db96fef71db8b8796 with name round-16
Round 17
Generated trajectories in 72.9 seconds
epoch: 0	train loss: 44971.58203125	(16.4s)
epoch: 1	train loss: 37201.72265625	(16.4s)
epoch: 2	train loss: 33943.16015625	(16.5s)
epoch: 3	train loss: 32142.572265625	(16.5s)
epoch: 4	train loss: 30892.373046875	(16.6s)
epoch: 5	train loss: 29912.39453125	(16.6s)
epoch: 6	train loss: 29269.30078125	(16.6s)
epoch: 7	train loss: 28915.14453125	(16.5s)
epoch: 8	train loss: 28460.716796875	(16.5s)
epoch: 9	train loss: 28201.66015625	(16.6s)
epoch: 10	train loss: 28522.9453125	(16.6s)
epoch: 11	train loss: 27504.60546875	(16.6s)
epoch: 12	train loss: 27291.34765625	(16.6s)
epoch: 13	train loss: 27905.66015625	(16.5s)
epoch: 14	train loss: 27154.1171875	(16.6s)
epoch: 15	train loss: 26938.716796875	(16.6s)
epoch: 16	train loss: 26381.96875	(16.6s)
epoch: 17	train loss: 26206.751953125	(16.6s)
epoch: 18	train loss: 26039.140625	(16.5s)
epoch: 19	train loss: 25762.02734375	(16.6s)
epoch: 20	train loss: 25706.16796875	(16.6s)
epoch: 21	train loss: 25631.884765625	(16.6s)
epoch: 22	train loss: 25808.0234375	(16.6s)
epoch: 23	train loss: 26837.625	(16.5s)
epoch: 24	train loss: 29354.23828125	(16.5s)
epoch: 25	train loss: 26683.96875	(16.6s)
epoch: 26	train loss: 25530.5234375	(16.5s)
epoch: 27	train loss: 25332.55078125	(16.5s)
epoch: 28	train loss: 24812.73828125	(16.5s)
epoch: 29	train loss: 24979.396484375	(16.5s)
epoch: 30	train loss: 24583.1796875	(16.5s)
epoch: 31	train loss: 24160.1015625	(16.5s)
epoch: 32	train loss: 24699.59375	(16.6s)
epoch: 33	train loss: 24361.216796875	(16.5s)
epoch: 34	train loss: 24198.216796875	(16.5s)
epoch: 35	train loss: 23832.712890625	(16.5s)
epoch: 36	train loss: 24547.404296875	(16.5s)
epoch: 37	train loss: 23592.0703125	(16.5s)
epoch: 38	train loss: 24255.11328125	(16.4s)
epoch: 39	train loss: 25197.33984375	(16.4s)
epoch: 40	train loss: 26096.0703125	(16.5s)
epoch: 41	train loss: 24099.6953125	(16.6s)
epoch: 42	train loss: 23566.59765625	(16.5s)
epoch: 43	train loss: 23761.537109375	(16.5s)
epoch: 44	train loss: 23502.669921875	(16.5s)
epoch: 45	train loss: 23679.408203125	(16.5s)
epoch: 46	train loss: 23595.9296875	(16.5s)
epoch: 47	train loss: 23307.73046875	(16.5s)
epoch: 48	train loss: 23505.091796875	(16.5s)
epoch: 49	train loss: 24335.421875	(16.5s)
epoch: 50	train loss: 23728.037109375	(16.5s)
epoch: 51	train loss: 23421.6015625	(16.6s)
epoch: 52	train loss: 23483.541015625	(16.6s)
epoch: 53	train loss: 24146.6875	(16.6s)
epoch: 54	train loss: 23208.90625	(16.5s)
epoch: 55	train loss: 24683.02734375	(16.5s)
epoch: 56	train loss: 24085.59765625	(16.6s)
epoch: 57	train loss: 23611.345703125	(16.6s)
epoch: 58	train loss: 24194.802734375	(16.5s)
epoch: 59	train loss: 23420.40625	(16.5s)
epoch: 60	train loss: 22916.033203125	(16.5s)
epoch: 61	train loss: 22559.70703125	(16.5s)
epoch: 62	train loss: 22641.33984375	(16.5s)
epoch: 63	train loss: 22855.6171875	(16.5s)
epoch: 64	train loss: 22352.501953125	(16.5s)
epoch: 65	train loss: 22268.408203125	(16.5s)
epoch: 66	train loss: 22251.17578125	(16.5s)
epoch: 67	train loss: 22342.96875	(16.6s)
epoch: 68	train loss: 22459.12109375	(16.5s)
epoch: 69	train loss: 22675.298828125	(16.5s)
epoch: 70	train loss: 22129.265625	(16.5s)
epoch: 71	train loss: 22008.009765625	(16.5s)
epoch: 72	train loss: 22236.775390625	(16.6s)
epoch: 73	train loss: 22240.490234375	(16.5s)
epoch: 74	train loss: 22562.19921875	(16.5s)
epoch: 75	train loss: 21932.369140625	(16.5s)
epoch: 76	train loss: 22320.62890625	(16.5s)
epoch: 77	train loss: 22666.326171875	(16.5s)
epoch: 78	train loss: 24005.505859375	(16.5s)
epoch: 79	train loss: 24078.443359375	(16.5s)
epoch: 80	train loss: 23507.408203125	(16.5s)
epoch: 81	train loss: 26103.11328125	(16.5s)
epoch: 82	train loss: 23856.916015625	(16.5s)
epoch: 83	train loss: 22627.697265625	(16.5s)
epoch: 84	train loss: 22135.552734375	(16.5s)
epoch: 85	train loss: 21636.677734375	(16.5s)
epoch: 86	train loss: 21480.15234375	(16.5s)
epoch: 87	train loss: 21815.32421875	(16.5s)
epoch: 88	train loss: 21639.78515625	(16.5s)
epoch: 89	train loss: 22105.52734375	(16.5s)
epoch: 90	train loss: 21841.16015625	(16.5s)
epoch: 91	train loss: 21942.80859375	(16.5s)
epoch: 92	train loss: 21717.11328125	(16.5s)
epoch: 93	train loss: 22072.484375	(16.5s)
epoch: 94	train loss: 22014.828125	(16.5s)
epoch: 95	train loss: 22206.58203125	(16.5s)
epoch: 96	train loss: 22201.75	(16.5s)
epoch: 97	train loss: 22103.556640625	(16.5s)
epoch: 98	train loss: 22064.71484375	(16.5s)
epoch: 99	train loss: 22180.216796875	(16.5s)
Evaluating model on 200 episodes
0.002653150324476883
0.0044792520347982645
0.002806723195438584
0.005344641802366823
0.0016671576304361224
0.009522095633049807
0.007735445676371455
0.0014109975309111178
0.003938215008626382
0.006738625022990163
0.00321073061786592
0.003371019891346805
0.0045128104859031735
0.004423671448603272
0.0027454520750325173
0.0062371817184612155
0.0046537857269868255
0.005225115106441081
0.0023848950862884522
0.0033865367683271566
0.006917130667716265
0.004207531586871482
0.0024075990077108145
0.00274655360262841
0.0025976557517424226
0.0014274503628257662
0.0021821665577590466
0.005685559629152219
0.003261086024576798
0.003816251934040338
0.004753165373889108
0.002621109636190037
0.0024574286289862357
0.0031249831197783353
0.0038944661209825426
0.005238056677626446
0.007711085630580783
0.0013197000953368843
0.01131248944438994
0.0024706824333406985
0.005912038332705076
0.0017371706198900938
0.0038948062574490905
0.0026067313738167286
0.0027346858056262135
0.0024275866647561393
0.004076285433256999
0.003901783609762788
0.002485035016434267
0.0044046114780940115
0.004461552004795521
0.005704433913342655
0.004393161657693175
0.0029501520621124655
0.006819572485983372
0.002592350142852714
0.0015624130610376596
0.0024813543229053416
0.004393621027702466
0.004042839243387182
0.004848820390179753
0.003098355431575328
0.008616537030320615
0.0035296177957206964
0.006279589388416045
0.009112478059250861
0.005997640429995954
0.0017460478120483458
0.0020495833887252957
0.002767041267361492
0.002945486514363438
0.0036913633424167833
0.0016896739834919572
0.0019701701385201886
0.00470908097922802
0.00662046205252409
0.003029802261153236
0.00260119828938817
0.003025613375939429
0.0018432771321386099
0.003489635622827336
0.0064743327820906416
0.003560693721131732
0.004219000950494471
0.0017646905034780502
0.00571414825390093
0.0020648618519771844
0.006251338170841336
0.00794110563583672
0.001502626168075949
0.003029039711691439
0.0037419672201698027
0.0022834465780761093
0.004041779941568772
0.004261995293200016
0.0026899465592578053
0.0025899977423250674
0.0018750483868643641
0.004654391882165025
0.003083116258494556
0.0027574684160451093
0.0050118732421348495
0.003758374856261071
0.0017073682975023985
0.0034816654466946297
0.0054989239200949665
0.0012455580108508002
0.0037171082415928445
0.003383800076941649
0.0012559954193420708
0.004768766307582458
0.002369283582083881
0.0033512579393573105
0.00413952461288621
0.006194715388119221
0.002900635590776801
0.0016329815625795163
0.0024821332772262394
0.0073895954216519994
0.00782604447643583
0.004136705712880939
0.003107720961062504
0.0036538621818181126
0.0030568193178623915
0.002780908369459212
0.0030500334687530994
0.005785487592220306
0.0034028178779408336
0.0035086123971268535
0.0034279425046406685
Solved 130/200 episodes
0.0025318541317580047
Evaluated model in 23.6 seconds
Saved model for run
e58cb3f68e74461db96fef71db8b8796 with name round-17
Round 18
Generated trajectories in 71.9 seconds
epoch: 0	train loss: 42369.91796875	(16.3s)
epoch: 1	train loss: 35833.68359375	(16.2s)
epoch: 2	train loss: 33286.0546875	(16.4s)
epoch: 3	train loss: 31293.384765625	(16.4s)
epoch: 4	train loss: 29966.134765625	(16.4s)
epoch: 5	train loss: 29115.259765625	(16.4s)
epoch: 6	train loss: 28281.126953125	(16.4s)
epoch: 7	train loss: 28233.43359375	(16.4s)
epoch: 8	train loss: 28055.017578125	(16.3s)
epoch: 9	train loss: 27779.318359375	(16.4s)
epoch: 10	train loss: 27107.322265625	(16.4s)
epoch: 11	train loss: 28528.580078125	(16.3s)
epoch: 12	train loss: 26818.9296875	(16.4s)
epoch: 13	train loss: 26480.669921875	(16.4s)
epoch: 14	train loss: 26377.236328125	(16.4s)
epoch: 15	train loss: 25819.240234375	(16.4s)
epoch: 16	train loss: 25740.857421875	(16.5s)
epoch: 17	train loss: 25575.40625	(16.4s)
epoch: 18	train loss: 25276.0859375	(16.4s)
epoch: 19	train loss: 25123.994140625	(16.4s)
epoch: 20	train loss: 25134.46484375	(16.4s)
epoch: 21	train loss: 24850.369140625	(16.4s)
epoch: 22	train loss: 24703.865234375	(16.4s)
epoch: 23	train loss: 24876.162109375	(16.4s)
epoch: 24	train loss: 24782.166015625	(16.4s)
epoch: 25	train loss: 25225.287109375	(16.4s)
epoch: 26	train loss: 24901.900390625	(16.4s)
epoch: 27	train loss: 24414.830078125	(16.4s)
epoch: 28	train loss: 24124.892578125	(16.4s)
epoch: 29	train loss: 23997.455078125	(16.4s)
epoch: 30	train loss: 24054.712890625	(16.4s)
epoch: 31	train loss: 24125.60546875	(16.3s)
epoch: 32	train loss: 24228.716796875	(16.4s)
epoch: 33	train loss: 24131.087890625	(16.4s)
epoch: 34	train loss: 25212.953125	(16.4s)
epoch: 35	train loss: 26398.287109375	(16.4s)
epoch: 36	train loss: 26573.458984375	(16.4s)
epoch: 37	train loss: 24877.720703125	(16.4s)
epoch: 38	train loss: 24340.986328125	(16.2s)
epoch: 39	train loss: 23680.10546875	(16.2s)
epoch: 40	train loss: 23515.974609375	(16.2s)
epoch: 41	train loss: 23410.83203125	(16.2s)
epoch: 42	train loss: 23455.126953125	(16.2s)
epoch: 43	train loss: 23418.177734375	(16.2s)
epoch: 44	train loss: 23158.984375	(16.2s)
epoch: 45	train loss: 23253.470703125	(16.2s)
epoch: 46	train loss: 23172.171875	(16.2s)
epoch: 47	train loss: 23114.99609375	(16.3s)
epoch: 48	train loss: 24578.88671875	(16.2s)
epoch: 49	train loss: 24315.845703125	(16.2s)
epoch: 50	train loss: 24124.029296875	(16.2s)
epoch: 51	train loss: 24105.53515625	(16.2s)
epoch: 52	train loss: 23672.9921875	(16.2s)
epoch: 53	train loss: 23317.015625	(16.2s)
epoch: 54	train loss: 24202.044921875	(16.2s)
epoch: 55	train loss: 23268.10546875	(16.2s)
epoch: 56	train loss: 23909.60546875	(16.2s)
epoch: 57	train loss: 23085.6796875	(16.2s)
epoch: 58	train loss: 23217.20703125	(16.2s)
epoch: 59	train loss: 22940.091796875	(16.2s)
epoch: 60	train loss: 22874.009765625	(16.2s)
epoch: 61	train loss: 22641.455078125	(16.2s)
epoch: 62	train loss: 22235.4453125	(16.1s)
epoch: 63	train loss: 22313.125	(16.3s)
epoch: 64	train loss: 21910.33203125	(16.1s)
epoch: 65	train loss: 21873.408203125	(16.2s)
epoch: 66	train loss: 22121.6875	(16.2s)
epoch: 67	train loss: 21840.533203125	(16.3s)
epoch: 68	train loss: 21871.703125	(16.1s)
epoch: 69	train loss: 22008.646484375	(16.2s)
epoch: 70	train loss: 21681.9375	(16.2s)
epoch: 71	train loss: 21703.015625	(16.2s)
epoch: 72	train loss: 21648.859375	(16.2s)
epoch: 73	train loss: 22080.9609375	(16.3s)
epoch: 74	train loss: 24335.15625	(16.2s)
epoch: 75	train loss: 24024.83984375	(16.2s)
epoch: 76	train loss: 23517.654296875	(16.2s)
epoch: 77	train loss: 23413.59765625	(16.1s)
epoch: 78	train loss: 22575.08203125	(16.2s)
epoch: 79	train loss: 21960.255859375	(16.2s)
epoch: 80	train loss: 21663.021484375	(16.2s)
epoch: 81	train loss: 22255.814453125	(16.2s)
epoch: 82	train loss: 21739.5	(16.2s)
epoch: 83	train loss: 21597.86328125	(16.3s)
epoch: 84	train loss: 21545.21484375	(16.3s)
epoch: 85	train loss: 21731.216796875	(16.2s)
epoch: 86	train loss: 21684.892578125	(16.1s)
epoch: 87	train loss: 21629.0625	(16.2s)
epoch: 88	train loss: 21562.435546875	(16.2s)
epoch: 89	train loss: 21666.3984375	(16.1s)
epoch: 90	train loss: 21244.03515625	(16.2s)
epoch: 91	train loss: 21564.353515625	(16.2s)
epoch: 92	train loss: 21747.390625	(16.2s)
epoch: 93	train loss: 21494.8984375	(16.3s)
epoch: 94	train loss: 21493.240234375	(16.2s)
epoch: 95	train loss: 21779.076171875	(16.2s)
epoch: 96	train loss: 21827.140625	(16.2s)
epoch: 97	train loss: 21516.1171875	(16.2s)
epoch: 98	train loss: 21395.25	(16.2s)
epoch: 99	train loss: 21632.662109375	(16.2s)
Evaluating model on 200 episodes
0.0063617785926908255
0.002120535704307258
0.0029515890637412667
0.010418410828736211
0.0036901135075216493
0.0042197447502985595
0.0024170271935872734
0.0062569008829693
0.0031894710555206984
0.0012072646641172469
0.0017636424551407497
0.0029640712891705334
0.005062771611846983
0.004054945195093751
0.003612405247016189
0.004336896856936316
0.00261657025112072
0.0037181911369164786
0.0022098554957968495
0.0034931158181279896
0.0016891820123419166
0.003092207305599004
0.0032688364929830036
0.0035958956771840653
0.005040187737904489
0.004370524004722635
0.002462862292304635
0.004921259009279311
0.008385955006815493
0.002617493892709414
0.005732972853972266
0.005817161213296155
0.003690090379677713
0.0026785985101014376
0.0041978768616293865
0.003230485466441938
0.0037815117684658617
0.002485601755324751
0.002186494064517319
0.005616014314000495
0.003343410324305296
0.0033069581259042025
0.002572255519529184
0.002808106034838905
0.005239282082766294
0.007294819544767961
0.0023587802425026894
0.004082936537452042
0.005121676833368838
0.0012503005855251104
0.002432711965714892
0.001963490154594183
0.007907887280452996
0.004726711078546941
0.004580177972093225
0.0063916934304870665
0.00709622577091472
0.00342735901940614
0.005881477030925453
0.003068149283838769
0.006779709248803556
0.004037326405523345
0.002270615368615836
0.004818085883744061
0.0033206738298758864
0.0051063707408805685
0.00293341182017078
0.004043138280394487
0.0041293243994005024
0.003996877193761368
0.002047905756626278
0.004436749615706503
0.0030070708016864955
0.005247723369393498
0.003253817791119218
0.0018500412697903812
0.0017196755507029593
0.004117207058394949
0.005329320119926706
0.0028469579410739243
0.002556598192313686
0.0018717158818617463
0.00251289876177907
0.0023895326691369214
0.003841065801680088
0.005749405216192827
0.0017791248974390328
0.0063594609770613415
0.002905139481299557
0.0029306113719940186
0.0037487179739400744
0.002842696849256754
0.005872418056242168
0.0044904391979798675
0.002579387597506866
0.0009633605950511992
0.0064160250331042334
0.0020409251446835697
0.0037942332855891436
0.003784433822147548
0.0031591702718287706
0.004364978429900172
0.0041358452290296555
0.0019526846590451896
0.004491775519757842
0.00771868338342756
0.0017366496031172574
0.0031490072375163435
0.004381227927903335
0.001517741271527484
0.006229373067617417
0.00455849333666265
0.003594150666945747
0.002148170126019977
0.0034682080848142506
0.009579414152540267
0.005934560293098912
0.003143860357037435
0.005385693783561389
0.004949888486104707
0.0035496536875143647
0.10847272294631694
0.005052956364428003
0.004995884242816828
0.0044206536341724655
0.004024368198588491
0.005402803421020508
0.003339218604378402
0.0020462204120121896
Solved 129/200 episodes
0.003060025858442093
Evaluated model in 21.1 seconds
Saved model for run
e58cb3f68e74461db96fef71db8b8796 with name round-18
Round 19
Generated trajectories in 71.3 seconds
epoch: 0	train loss: 42671.6328125	(16.2s)
epoch: 1	train loss: 35728.5	(16.2s)
epoch: 2	train loss: 32771.7265625	(16.3s)
epoch: 3	train loss: 30947.162109375	(16.3s)
epoch: 4	train loss: 29625.142578125	(16.3s)
epoch: 5	train loss: 28737.7890625	(16.3s)
epoch: 6	train loss: 28005.708984375	(16.3s)
epoch: 7	train loss: 27441.947265625	(16.3s)
epoch: 8	train loss: 27153.97265625	(16.3s)
epoch: 9	train loss: 26971.19921875	(16.3s)
epoch: 10	train loss: 27086.392578125	(16.3s)
epoch: 11	train loss: 26998.625	(16.3s)
epoch: 12	train loss: 26718.580078125	(16.3s)
epoch: 13	train loss: 26111.5234375	(16.3s)
epoch: 14	train loss: 25789.494140625	(16.3s)
epoch: 15	train loss: 25750.947265625	(16.3s)
epoch: 16	train loss: 26258.23828125	(16.3s)
epoch: 17	train loss: 26489.380859375	(16.3s)
epoch: 18	train loss: 25660.220703125	(16.3s)
epoch: 19	train loss: 25314.240234375	(16.3s)
epoch: 20	train loss: 26649.802734375	(16.3s)
epoch: 21	train loss: 26004.26953125	(16.3s)
epoch: 22	train loss: 25060.220703125	(16.3s)
epoch: 23	train loss: 24877.294921875	(16.3s)
epoch: 24	train loss: 25412.591796875	(16.3s)
epoch: 25	train loss: 25272.634765625	(16.3s)
epoch: 26	train loss: 24505.65625	(16.4s)
epoch: 27	train loss: 24160.5390625	(16.3s)
epoch: 28	train loss: 24243.478515625	(16.3s)
epoch: 29	train loss: 24177.8125	(16.3s)
epoch: 30	train loss: 24207.193359375	(16.3s)
epoch: 31	train loss: 24324.205078125	(16.4s)
epoch: 32	train loss: 24148.564453125	(16.3s)
epoch: 33	train loss: 24097.234375	(16.3s)
epoch: 34	train loss: 24569.748046875	(16.3s)
epoch: 35	train loss: 24315.94921875	(16.3s)
epoch: 36	train loss: 25719.5078125	(16.4s)
epoch: 37	train loss: 23835.541015625	(16.3s)
epoch: 38	train loss: 23439.146484375	(16.3s)
epoch: 39	train loss: 23275.716796875	(16.3s)
epoch: 40	train loss: 23298.47265625	(16.3s)
epoch: 41	train loss: 23296.169921875	(16.3s)
epoch: 42	train loss: 23284.685546875	(16.3s)
epoch: 43	train loss: 23386.763671875	(16.3s)
epoch: 44	train loss: 23436.12109375	(16.3s)
epoch: 45	train loss: 23358.783203125	(16.3s)
epoch: 46	train loss: 23141.44921875	(16.3s)
epoch: 47	train loss: 23101.77734375	(16.3s)
epoch: 48	train loss: 23141.6015625	(16.3s)
epoch: 49	train loss: 23533.3828125	(16.3s)
epoch: 50	train loss: 22804.380859375	(16.3s)
epoch: 51	train loss: 22567.576171875	(16.3s)
epoch: 52	train loss: 22502.16015625	(16.3s)
epoch: 53	train loss: 22812.560546875	(16.3s)
epoch: 54	train loss: 22967.85546875	(16.3s)
epoch: 55	train loss: 23400.546875	(16.3s)
epoch: 56	train loss: 25113.3984375	(16.3s)
epoch: 57	train loss: 23277.26171875	(16.3s)
epoch: 58	train loss: 22726.056640625	(16.3s)
epoch: 59	train loss: 23102.35546875	(16.3s)
epoch: 60	train loss: 25368.390625	(16.3s)
epoch: 61	train loss: 24651.84375	(16.3s)
epoch: 62	train loss: 24326.794921875	(16.3s)
epoch: 63	train loss: 23294.466796875	(16.3s)
epoch: 64	train loss: 25574.189453125	(16.3s)
epoch: 65	train loss: 23854.841796875	(16.3s)
epoch: 66	train loss: 22756.935546875	(16.3s)
epoch: 67	train loss: 22449.498046875	(16.3s)
epoch: 68	train loss: 22153.11328125	(16.3s)
epoch: 69	train loss: 22431.603515625	(16.3s)
epoch: 70	train loss: 22200.39453125	(16.3s)
epoch: 71	train loss: 22292.322265625	(16.3s)
epoch: 72	train loss: 22152.03515625	(16.3s)
epoch: 73	train loss: 22066.85546875	(16.3s)
epoch: 74	train loss: 21999.896484375	(16.3s)
epoch: 75	train loss: 22250.345703125	(16.3s)
epoch: 76	train loss: 22047.21875	(16.3s)
epoch: 77	train loss: 21813.916015625	(16.3s)
epoch: 78	train loss: 21988.759765625	(16.3s)
epoch: 79	train loss: 21950.529296875	(16.4s)
epoch: 80	train loss: 22412.46484375	(16.3s)
epoch: 81	train loss: 21791.494140625	(16.3s)
epoch: 82	train loss: 23553.0546875	(16.3s)
epoch: 83	train loss: 22307.26953125	(16.4s)
epoch: 84	train loss: 21962.919921875	(16.3s)
epoch: 85	train loss: 22816.9921875	(16.3s)
epoch: 86	train loss: 21877.791015625	(16.3s)
epoch: 87	train loss: 22001.525390625	(16.3s)
epoch: 88	train loss: 21830.236328125	(16.3s)
epoch: 89	train loss: 22227.853515625	(16.3s)
epoch: 90	train loss: 21658.1328125	(16.3s)
epoch: 91	train loss: 22053.306640625	(16.3s)
epoch: 92	train loss: 22508.625	(16.3s)
epoch: 93	train loss: 22249.228515625	(16.3s)
epoch: 94	train loss: 21663.6015625	(16.3s)
epoch: 95	train loss: 21337.91796875	(16.3s)
epoch: 96	train loss: 21106.763671875	(16.3s)
epoch: 97	train loss: 21510.673828125	(16.3s)
epoch: 98	train loss: 21402.833984375	(16.3s)
epoch: 99	train loss: 21963.8984375	(16.3s)
Evaluating model on 200 episodes
0.002819519999320619
0.00455139421059617
0.0013303204323165119
0.004364563981653191
0.002541328431107104
0.0019396524294279516
0.0031059153843671083
0.0016834877314977348
0.002239671943243593
0.0018622436909936368
0.001965267331494639
0.00558913333225064
0.0037352133222157136
0.001411965349689126
0.0025291736237704754
0.0018917839042842388
0.0019976806070189923
0.0023566073893258968
0.003108070231974125
0.0020367075533916554
0.003253060975112021
0.0021387346350820735
0.0027433146024122834
0.002685072342865169
0.0015414973410467307
0.001478407202133288
0.0029334278442547657
0.0036222178355923723
0.0023129509936552495
0.0027289257656472423
0.004277536373895903
0.002646121589350514
0.003209286369383335
0.005719207333944117
0.003937661938834935
0.003359222365543246
0.009459289722144604
0.0026123519831647477
0.016179996465022366
0.003366420933161862
0.00259151155478321
0.0031063096054519215
0.002210928340597699
0.0028715617256239055
0.0020895764173474163
0.0012162744969828054
0.00357327905173103
0.0018651238254581888
0.0031475270710264644
0.0023344397777691483
0.0014202881914873917
0.002102895377902314
0.0018457667902112007
0.0021624242363031954
0.0025137155995859453
0.005171042401343584
0.0018481079750927165
0.007539942123306294
0.004234455118421465
0.002518519468139857
0.0037721062544733286
0.002697978261858225
0.0023246377240866423
0.0025378857098985463
0.0026328012463636696
0.0028939702024217695
0.0037075303747163466
0.004383115544139097
0.0025048880779650062
0.0032247162889689207
0.0020027775899507105
0.0045238265356601914
0.0023244190379045904
0.0027068683702964336
0.004390964895719662
0.0032213647675234823
0.00362214973817269
0.004531856568064541
0.0045610926754307
0.0069638279798839775
0.006163662654580548
0.0024848662433214486
0.003215231408830732
0.0026101065644373498
0.002452367509249598
0.0033923899269818016
0.004421367930869262
0.007558082995404091
0.003981475776527077
0.0018314396729692817
0.0026840237551368773
0.0019872445409419015
0.002145050986049076
0.0028427343155878284
0.003442645502218511
0.0029136628145352006
0.0064685372926760465
0.004303539590910077
0.0010811345127876848
0.003046147059649229
0.0012677387324705098
0.002092267823172733
0.0018719283980317414
0.002807941607898101
0.002477586720488034
0.002416731309494935
0.0023719685850664973
0.0033019006252288817
0.001730275951558724
0.004357498692115769
0.0026335842994740233
0.0026662276359274983
0.005037811351940036
0.002519183442927897
0.0038725861348211767
0.003311886321171187
0.004649835671963436
0.0021428039763122797
0.002559979174596568
Solved 119/200 episodes
0.0019113615999628694
Evaluated model in 25.1 seconds
Saved model for run
e58cb3f68e74461db96fef71db8b8796 with name round-19
Completed training in 34962.4 seconds
Solved 18/200 episodes
Solved 30/200 episodes
Solved 38/200 episodes
Solved 40/200 episodes
Solved 50/200 episodes
Solved 63/200 episodes
Solved 87/200 episodes
Solved 87/200 episodes
Solved 100/200 episodes
Solved 107/200 episodes
Solved 105/200 episodes
Solved 101/200 episodes
Solved 93/200 episodes
Solved 120/200 episodes
Solved 122/200 episodes
Solved 126/200 episodes
Solved 122/200 episodes
Solved 130/200 episodes
Solved 129/200 episodes
Solved 119/200 episodes
