Starting run:
fff9420d2eb04e0899b34930e9038a34
N: 	20000
MODEL: 	hmm-homo
ABSTRACT_PEN: 	1.0
FINE_TUNE: 	False
MUZERO: 	False
params=Namespace(n=20000, b=10, abstract_pen=1.0, model='hmm-homo', seed=1, lr=0.0001, abstract_dim=32, tau_noise_std=0.0, freeze=False, load=False, ellis=False, no_log=False, fine_tune=False, tau_precompute=False, replace_trans_net=False, batch_norm=False, no_tau_norm=False, relational_micro=False, toy_test=False, separate_option_nets=False, gumbel=False, g_start_temp=1, g_stop_temp=1, num_categories=8, shrink_micro_net=False, shrink_loss_scale=1, length=(1, 2, 3, 4), muzero=False, muzero_scratch=False, num_test=200, test_every=60, save_every=180, neurosym=False, batch_size=32, traj_updates=10000000.0, model_load_path='models/e14b78d01cc548239ffd57286e59e819.pt', gumbel_sched=False, device='NVIDIA GeForce RTX 2080 Ti', id='fff9420d2eb04e0899b34930e9038a34')
wandb: Currently logged in as: simonalford42. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.12.21
wandb: Run data is saved locally in /home/sca63/abstraction/wandb/run-20220728_161342-2u0mn2k8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-cloud-112
wandb: â­ï¸ View project at https://wandb.ai/simonalford42/abstraction
wandb: ğŸš€ View run at https://wandb.ai/simonalford42/abstraction/runs/2u0mn2k8
Net has 41898 parameters
Solved 0/200 episodes
Solved 32/200 episodes
Solved 40/200 episodes
Saved model at models/fff9420d2eb04e0899b34930e9038a34-epoch-180.pt
Solved 30/200 episodes
Solved 27/200 episodes
Solved 22/200 episodes
Saved model at models/fff9420d2eb04e0899b34930e9038a34-epoch-355.pt
Solved 32/200 episodes
Solved 40/200 episodes
Solved 26/200 episodes
Saved model at models/fff9420d2eb04e0899b34930e9038a34.pt
N: 	20000
MODEL: 	hmm-homo
ABSTRACT_PEN: 	1.0
FINE_TUNE: 	False
MUZERO: 	False
Completed training in 30956.4 seconds
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: \ 0.010 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: | 0.010 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: / 0.012 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: - 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: \ 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: | 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: / 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: - 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: \ 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:     loss â–ˆâ–…â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: test/acc â–â–‡â–ˆâ–†â–†â–…â–‡â–ˆâ–†
wandb: 
wandb: Run summary:
wandb:     loss 129599.25
wandb: test/acc 0.13
wandb: 
wandb: Synced classic-cloud-112: https://wandb.ai/simonalford42/abstraction/runs/2u0mn2k8
wandb: Synced 6 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220728_161342-2u0mn2k8/logs
