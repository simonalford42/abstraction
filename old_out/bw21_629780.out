wandb: Currently logged in as: simonalford42. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.12.20
wandb: Run data is saved locally in /home/sca63/abstraction/wandb/run-20220629_162157-1xm0kcm4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-fire-22
wandb: â­ï¸ View project at https://wandb.ai/simonalford42/abstraction
wandb: ğŸš€ View run at https://wandb.ai/simonalford42/abstraction/runs/1xm0kcm4
Starting run:
d4e83656a7b7426291e2557534dfccff
params: Namespace(n=20000, b=10, abstract_pen=0.0, model='hmm', lr=0.0008, abstract_dim=32, tau_noise_std=0.0, freeze=False, toy_test=False, load=False, seed=1, ellis=False, no_log=False, fine_tune=False, tau_precompute=False, length=(1, 2, 3, 4), muzero=False, test_every=90, save_every=180, num_test=200, shrink_micro_net=False, shrink_loss_scale=1, gumbel=False, g_start_temp=1, g_stop_temp=1, num_categories=8, replace_trans_net=False, batch_norm=False, no_tau_norm=False, relational_micro=False, separate_option_nets=False, batch_size=32, traj_updates=10000000.0, model_load_path='models/e14b78d01cc548239ffd57286e59e819.pt', gumbel_sched=False, device='NVIDIA RTX A5000', id='d4e83656a7b7426291e2557534dfccff')
Net has 156468 parameters
WARNING: tau norm dim disabled
Saved model at models/d4e83656a7b7426291e2557534dfccff-epoch-220.pt
Saved model at models/d4e83656a7b7426291e2557534dfccff-epoch-441.pt
Saved model at models/d4e83656a7b7426291e2557534dfccff.pt
Completed training in 24838.7 seconds
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.691 MB of 0.691 MB uploaded (0.000 MB deduped)wandb: \ 0.691 MB of 0.691 MB uploaded (0.000 MB deduped)wandb: | 0.691 MB of 0.706 MB uploaded (0.000 MB deduped)wandb: / 0.691 MB of 0.706 MB uploaded (0.000 MB deduped)wandb: - 0.706 MB of 0.706 MB uploaded (0.000 MB deduped)wandb: \ 0.706 MB of 0.706 MB uploaded (0.000 MB deduped)wandb: | 0.706 MB of 0.706 MB uploaded (0.000 MB deduped)wandb: / 0.706 MB of 0.706 MB uploaded (0.000 MB deduped)wandb: - 0.706 MB of 0.706 MB uploaded (0.000 MB deduped)wandb: \ 0.706 MB of 0.706 MB uploaded (0.000 MB deduped)wandb: | 0.706 MB of 0.706 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                 loss â–ˆâ–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             test/acc â–â–„â–ˆâ–ˆâ–ˆ
wandb:     test/cc_loss_avg â–â–ˆâ–†â–†â–†
wandb: test/solved_pred_acc â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                epoch 499
wandb:                 loss 3713.04876
wandb:             test/acc 0.855
wandb:     test/cc_loss_avg 0.08267
wandb: test/solved_pred_acc 1.0
wandb: 
wandb: Synced fluent-fire-22: https://wandb.ai/simonalford42/abstraction/runs/1xm0kcm4
wandb: Synced 6 W&B file(s), 103 media file(s), 3 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220629_162157-1xm0kcm4/logs
