Using torch device NVIDIA GeForce RTX 3090
net: causal
cc_weight: 0.0
params: {'epochs': 100, 'lr': 0.0008, 'n': 5000}
Net has 207442 parameters
Round 0
Generated trajectories in 69.7 seconds
epoch: 0	train loss: 140502.53125	(16.7s)
epoch: 1	train loss: 110428.1953125	(15.7s)
epoch: 2	train loss: 99959.328125	(15.7s)
epoch: 3	train loss: 83295.4921875	(15.7s)
epoch: 4	train loss: 71077.8359375	(15.7s)
epoch: 5	train loss: 63092.3203125	(15.6s)
epoch: 6	train loss: 56585.26953125	(15.6s)
epoch: 7	train loss: 55421.89453125	(15.6s)
epoch: 8	train loss: 50629.328125	(15.6s)
epoch: 9	train loss: 49097.1640625	(15.6s)
epoch: 10	train loss: 47980.73046875	(15.7s)
epoch: 11	train loss: 46456.3046875	(15.7s)
epoch: 12	train loss: 45704.578125	(15.7s)
epoch: 13	train loss: 44336.3515625	(15.7s)
epoch: 14	train loss: 42899.41015625	(15.7s)
epoch: 15	train loss: 42075.66015625	(15.9s)
epoch: 16	train loss: 41394.96484375	(16.1s)
epoch: 17	train loss: 40692.5078125	(16.0s)
epoch: 18	train loss: 40375.515625	(16.0s)
epoch: 19	train loss: 39844.51171875	(15.9s)
epoch: 20	train loss: 39472.37109375	(15.9s)
epoch: 21	train loss: 38522.6953125	(16.0s)
epoch: 22	train loss: 37972.83984375	(15.9s)
epoch: 23	train loss: 37489.52734375	(16.0s)
epoch: 24	train loss: 36832.75390625	(15.9s)
epoch: 25	train loss: 36516.5703125	(16.0s)
epoch: 26	train loss: 35992.76171875	(16.0s)
epoch: 27	train loss: 35730.75390625	(15.9s)
epoch: 28	train loss: 35550.88671875	(16.0s)
epoch: 29	train loss: 34914.59765625	(15.9s)
epoch: 30	train loss: 35048.00390625	(16.0s)
epoch: 31	train loss: 34246.98046875	(16.0s)
epoch: 32	train loss: 33746.375	(15.9s)
epoch: 33	train loss: 33380.3671875	(16.0s)
epoch: 34	train loss: 33366.88671875	(15.9s)
epoch: 35	train loss: 33580.98046875	(15.9s)
epoch: 36	train loss: 32790.765625	(16.0s)
epoch: 37	train loss: 32351.427734375	(15.9s)
epoch: 38	train loss: 32102.150390625	(16.0s)
epoch: 39	train loss: 31841.83984375	(16.0s)
epoch: 40	train loss: 31830.287109375	(15.9s)
epoch: 41	train loss: 31557.541015625	(16.0s)
epoch: 42	train loss: 31387.689453125	(15.9s)
epoch: 43	train loss: 31370.212890625	(15.9s)
epoch: 44	train loss: 31556.224609375	(15.9s)
epoch: 45	train loss: 31327.201171875	(16.0s)
epoch: 46	train loss: 30946.556640625	(15.9s)
epoch: 47	train loss: 30716.466796875	(15.9s)
epoch: 48	train loss: 31172.31640625	(15.9s)
epoch: 49	train loss: 30359.845703125	(15.9s)
epoch: 50	train loss: 30051.3828125	(15.9s)
epoch: 51	train loss: 29873.060546875	(15.9s)
epoch: 52	train loss: 30365.603515625	(15.9s)
epoch: 53	train loss: 29872.3671875	(16.0s)
epoch: 54	train loss: 29444.55078125	(16.0s)
epoch: 55	train loss: 29322.58984375	(15.9s)
epoch: 56	train loss: 29155.59375	(15.9s)
epoch: 57	train loss: 29155.177734375	(15.9s)
epoch: 58	train loss: 29059.65234375	(16.0s)
epoch: 59	train loss: 28401.119140625	(15.9s)
epoch: 60	train loss: 28172.673828125	(15.9s)
epoch: 61	train loss: 27896.474609375	(15.9s)
epoch: 62	train loss: 28228.740234375	(15.9s)
epoch: 63	train loss: 29513.494140625	(15.9s)
epoch: 64	train loss: 27532.82421875	(15.9s)
epoch: 65	train loss: 27639.0703125	(15.9s)
epoch: 66	train loss: 27654.705078125	(15.9s)
epoch: 67	train loss: 27156.40234375	(15.9s)
epoch: 68	train loss: 27163.984375	(15.9s)
epoch: 69	train loss: 27075.96875	(16.0s)
epoch: 70	train loss: 26927.091796875	(15.9s)
epoch: 71	train loss: 26725.28125	(15.9s)
epoch: 72	train loss: 26863.96484375	(15.9s)
epoch: 73	train loss: 26565.63671875	(15.9s)
epoch: 74	train loss: 26759.541015625	(16.1s)
epoch: 75	train loss: 26313.671875	(15.9s)
epoch: 76	train loss: 26365.05078125	(16.0s)
epoch: 77	train loss: 25930.337890625	(15.9s)
epoch: 78	train loss: 25506.943359375	(15.9s)
epoch: 79	train loss: 25225.68359375	(15.9s)
epoch: 80	train loss: 25236.3671875	(15.9s)
epoch: 81	train loss: 24855.732421875	(15.9s)
epoch: 82	train loss: 24927.607421875	(15.9s)
epoch: 83	train loss: 25332.8984375	(15.9s)
epoch: 84	train loss: 24374.4140625	(15.9s)
epoch: 85	train loss: 24205.072265625	(15.9s)
epoch: 86	train loss: 23954.0625	(15.9s)
epoch: 87	train loss: 23980.900390625	(15.9s)
epoch: 88	train loss: 23834.470703125	(15.9s)
epoch: 89	train loss: 23750.25390625	(15.9s)
epoch: 90	train loss: 23485.216796875	(16.0s)
epoch: 91	train loss: 26210.416015625	(15.9s)
epoch: 92	train loss: 23989.810546875	(15.9s)
epoch: 93	train loss: 23697.548828125	(15.9s)
epoch: 94	train loss: 23833.255859375	(15.9s)
epoch: 95	train loss: 23398.46484375	(15.9s)
epoch: 96	train loss: 23108.982421875	(15.9s)
epoch: 97	train loss: 23734.11328125	(15.9s)
epoch: 98	train loss: 23099.419921875	(15.9s)
epoch: 99	train loss: 23231.478515625	(15.9s)
Evaluating model on 200 episodes
Evaluated model in 0.3 seconds
Completed training in 1679.8 seconds
Traceback (most recent call last):
  File "/home/sca63/abstraction/main.py", line 172, in <module>
    boxworld_main()
  File "/home/sca63/abstraction/main.py", line 157, in boxworld_main
    boxworld_outer_sv(
  File "/home/sca63/abstraction/main.py", line 82, in boxworld_outer_sv
    box_world.eval_options_model(net.control_net, env, n=num_test)
  File "/home/sca63/abstraction/box_world.py", line 483, in eval_options_model
    tau_goal = control_net.macro_transition(tau, current_option)
  File "/home/sca63/abstraction/abstract.py", line 98, in macro_transition
    return self.macro_transitions(t.unsqueeze(0),
  File "/home/sca63/abstraction/abstract.py", line 123, in macro_transitions
    t_i2 = torch.cat((t_i2, b_onehots), dim=1)  # (T*nb, t + b)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper___cat)
